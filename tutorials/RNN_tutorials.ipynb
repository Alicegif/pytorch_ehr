{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we quickly demonstrate how to utilize different mudules in our package.\n",
    "We will go through how to use our packages for 2 major sections:\n",
    "1. Process data through our dataloader \n",
    "2. Specify parameters and train\n",
    "***\n",
    "* The parts where you can take the most control (modify to suit your needs) will have explanations highlighted in **bold**. \n",
    "* Hyperparameters should be self-explanatory with details in options() function. \n",
    "* You can also find commments at the beginning of each cell for their functionalities in gerneral\n",
    "\n",
    "### Step0. Load libraries and our modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Nov 28 12:57:40 2018\n",
    "@author: ginnyzhu\n",
    "\"\"\"\n",
    "from __future__ import print_function, division\n",
    "from io import open\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "#import self-defined modules\n",
    "#models, utils, and Dataloader\n",
    "#sys.path.insert() only for jupyter notebook imports\n",
    "import sys\n",
    "sys.path.insert(0, '../ehr_pytorch')\n",
    "import models as model \n",
    "from EHRDataloader import EHRdataFromPickles, EHRdataloader \n",
    "import utils as ut #:)))) \n",
    "from EHREmb import EHREmbeddings\n",
    "\n",
    "#silly ones\n",
    "from termcolor import colored\n",
    "\n",
    "# check GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args, slightly modified from main.py file to be more compatible with jupyter notebook \n",
    "#all args provide default values, so you can run the whole notebook without changing/providing any args\n",
    "#args ordered by dataloader, model, and training sections\n",
    "def options():\n",
    "    parser = argparse.ArgumentParser(description='Predictive Analytics on EHR with Pytorch')\n",
    "    \n",
    "    #EHRdataloader \n",
    "    parser.add_argument('-root_dir', type = str, default = '../data/' , \n",
    "                        help='the path to the folders with pickled file(s)')\n",
    "    parser.add_argument('-file', type = str, default = 'hf.train' , \n",
    "                        help='the name of pickled files')\n",
    "    parser.add_argument('-test_ratio', type = float, default = 0.2, \n",
    "                        help='test data size [default: 0.2]')\n",
    "    parser.add_argument('-valid_ratio', type = float, default = 0.1, \n",
    "                        help='validation data size [default: 0.1]')\n",
    "    \n",
    "    #EHRmodel\n",
    "    parser.add_argument('-which_model', type = str, default = 'DRNN', \n",
    "                        help='choose from {\"RNN\",\"DRNN\",\"QRNN\",\"LR\"}') \n",
    "    parser.add_argument('-cell_type', type = str, default = 'GRU', \n",
    "                        help='For RNN based models, choose from {\"RNN\", \"GRU\", \"LSTM\", \"QRNN\" (for QRNN model only)}')\n",
    "    parser.add_argument('-input_size', type = list, default =[15817], \n",
    "                        help='''input dimension(s), decide which embedding types to use. \n",
    "                        If len of 1, then  1 embedding; \n",
    "                        len of 3, embedding medical, diagnosis and others separately (3 embeddings) \n",
    "                        [default:[15817]]''')\n",
    "    parser.add_argument('-embed_dim', type=int, default=128, \n",
    "                        help='number of embedding dimension [default: 128]')\n",
    "    parser.add_argument('-hidden_size', type=int, default=128, \n",
    "                        help='size of hidden layers [default: 128]')\n",
    "    parser.add_argument('-dropout_r', type=float, default=0.1, \n",
    "                        help='the probability for dropout[default: 0.1]')\n",
    "    parser.add_argument('-n_layers', type=int, default=3, \n",
    "                        help='''number of Layers, \n",
    "                        for Dilated RNNs, dilations will increase exponentialy with mumber of layers [default: 1]''')\n",
    "    parser.add_argument('-bii', type=bool, default=False, \n",
    "                        help='indicator of whether Bi-directin is activated. [default: False]')\n",
    "    parser.add_argument('-time', type=bool, default=False, \n",
    "                        help='indicator of whether time is incorporated into embedding. [default: False]')\n",
    "    parser.add_argument('-preTrainEmb', type= str, default='', \n",
    "                        help='path to pretrained embeddings file. [default:'']')\n",
    "    parser.add_argument(\"-output_dir\",type=str, default= '../models/', \n",
    "                        help=\"The output directory where the best model will be saved and logs written [default: we will create'../models/'] \")\n",
    "    \n",
    "    # training \n",
    "    parser.add_argument('-lr', type=float, default=10**-4, \n",
    "                        help='learning rate [default: 0.0001]')\n",
    "    parser.add_argument('-L2', type=float, default=10**-4, \n",
    "                        help='L2 regularization [default: 0.0001]')\n",
    "    parser.add_argument('-epochs', type=int, default= 100, \n",
    "                        help='number of epochs for training [default: 100]')\n",
    "    parser.add_argument('-patience', type=int, default= 20, \n",
    "                        help='number of stagnant epochs to wait before terminating training [default: 20]')\n",
    "    parser.add_argument('-batch_size', type=int, default=128, \n",
    "                        help='batch size for training, validation or test [default: 128]')\n",
    "    parser.add_argument('-optimizer', type=str, default='adam', \n",
    "                        choices=  ['adam','adadelta','adagrad', 'adamax', 'asgd','rmsprop', 'rprop', 'sgd'], \n",
    "                        help='Select which optimizer to train [default: adam]. Upper/lower case does not matter') \n",
    "    #parser.add_argument('-cuda', type= bool, default=True, help='whether GPU is available [default:True]')\n",
    "    args = parser.parse_args([])\n",
    "    return args "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StepX: You can modify parameters here to suit your own need\n",
    "\n",
    "* All parameters have explanations in the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(L2=0.0001, batch_size=128, bii=False, cell_type='GRU', dropout_r=0.2, embed_dim=256, epochs=100, file='hf.train', hidden_size=256, input_size=[15817], lr=0.0001, n_layers=2, optimizer='adam', output_dir='../models/', patience=20, preTrainEmb='', root_dir='../data/', test_ratio=0.2, time=False, valid_ratio=0.1, which_model='RNN')\n"
     ]
    }
   ],
   "source": [
    "args = options()\n",
    "##Update the args here if you dont want to use the default ones\n",
    "##start an example\n",
    "args.which_model = 'RNN'\n",
    "args.cell_type = 'GRU'\n",
    "args.embed_dim = 256\n",
    "args.hidden_size = 256\n",
    "args.dropout_r = 0.2\n",
    "args.n_layers = 2\n",
    "##end\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Loading and preparing data...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "####Step1. Data preparation\n",
    "#By default, prevent sort (on visit length) before splitting, if splitting\n",
    "#Gotta specify your split ratios here if intend to split on non-default split ratios\n",
    "#First load your data\n",
    "print(colored(\"\\nLoading and preparing data...\", 'green'))    \n",
    "data = EHRdataFromPickles(root_dir = args.root_dir, \n",
    "                          file = args.file, \n",
    "                          sort= False,\n",
    "                          test_ratio = args.test_ratio, \n",
    "                          valid_ratio = args.valid_ratio) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| data_description   | data                                                                |\n",
      "|--------------------+---------------------------------------------------------------------|\n",
      "| patient_id         | 310831                                                              |\n",
      "| label              | 0                                                                   |\n",
      "| visit_time         | [list([0])]                                                         |\n",
      "| visit_codes        | [list([38, 2108, 171, 263, 16, 47, 260, 42, 141, 52, 244, 28, 30])] |\n",
      "[310831, 0, [[[0], [38, 2108, 171, 263, 16, 47, 260, 42, 141, 52, 244, 28, 30]]]]\n",
      "\u001b[32m\n",
      "Sample data after split:\u001b[0m\n",
      "train: [12966320, 0, [[[0], [38, 2196, 124, 222, 16, 105, 91, 88, 181, 52, 311, 108, 30]]]]\n",
      "test: [12884531, 0, [[[0], [38, 2034, 196, 377, 16, 105, 23, 42, 181, 52, 215, 108, 30]]]]\n",
      "validation: [13486254, 0, [[[0], [38, 2010, 1997, 130, 33, 180, 16, 47, 103, 42, 181, 52, 183, 108, 30]]]]\n",
      "\u001b[32m\n",
      "Sample data lengths for train, test and validation:\u001b[0m\n",
      "9917 2833 1416\n"
     ]
    }
   ],
   "source": [
    "#see an example of our pickle data\n",
    "#40 is the index\n",
    "#it will print out a formatted table of what each value mean and how they are organized in the file\n",
    "print(data.__getitem__(40, seeDescription = True)) \n",
    "\n",
    "# Dataloader splits\n",
    "train, test, valid = data.__splitdata__()\n",
    "# can comment out this part if you dont want to know what's going on here\n",
    "print(colored(\"\\nSample data after split:\", 'green'))\n",
    "# an example from train, test, and valiation\n",
    "print(\n",
    "  \"train: {}\".format(train[-1]),\n",
    "  \"test: {}\".format(test[-1]),\n",
    "  \"validation: {}\".format(valid[-1]), sep='\\n')\n",
    "print(colored(\"\\nSample data lengths for train, test and validation:\", 'green'))\n",
    "print(len(train), len(test), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate loader for train, test, validation\n",
    "#if you have different files, you need to load them separately into EHRdataFromPickles()\n",
    "#and then use EHRdataloader() on each\n",
    "#dataloader's default will sort data based on length of visits and then split into batches with default batch_size/of your choice\n",
    "trainloader = EHRdataloader(train) \n",
    "validloader = EHRdataloader(valid)\n",
    "testloader = EHRdataloader(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. Model loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depending on different models, model parameters might have different choices.\n",
    "#e.g. if you set bi = True for DRNN or QRNN, it will throw you warnings and implement correct bi =False instead\n",
    "if args.which_model == 'RNN': \n",
    "    ehr_model = model.EHR_RNN(input_size= args.input_size, \n",
    "                              embed_dim=args.embed_dim, \n",
    "                              hidden_size= args.hidden_size,\n",
    "                              n_layers= args.n_layers,\n",
    "                              dropout_r=args.dropout_r,\n",
    "                              cell_type=args.cell_type,\n",
    "                              bii= args.bii,\n",
    "                              time= args.time,\n",
    "                              preTrainEmb= args.preTrainEmb) \n",
    "elif args.which_model == 'DRNN': \n",
    "    ehr_model = model.EHR_DRNN(input_size= args.input_size, \n",
    "                              embed_dim=args.embed_dim, \n",
    "                              hidden_size= args.hidden_size,\n",
    "                              n_layers= args.n_layers,\n",
    "                              dropout_r=args.dropout_r, #default =0 \n",
    "                              cell_type=args.cell_type, #default = 'GRU'\n",
    "                              bii= False, #DRNN\n",
    "                              time = args.time, \n",
    "                              preTrainEmb= args.preTrainEmb)     \n",
    "elif args.which_model == 'QRNN': \n",
    "    ehr_model = model.EHR_DRNN(input_size= args.input_size, \n",
    "                              embed_dim=args.embed_dim, \n",
    "                              hidden_size= args.hidden_size,\n",
    "                              n_layers= args.n_layers,\n",
    "                              dropout_r=args.dropout_r, #default =0.1\n",
    "                              cell_type= 'QRNN', #doesn't support normal cell types\n",
    "                              bii= False, #QRNN doesn't support bi\n",
    "                              time = args.time, \n",
    "                              preTrainEmb= args.preTrainEmb)  \n",
    "else: \n",
    "    ehr_model = model.EHR_LR_emb(input_size = args.input_size,\n",
    "                                 embed_dim = args.embed_dim,\n",
    "                                 preTrainEmb= args.preTrainEmb)\n",
    "#make sure cuda is working\n",
    "if use_cuda:\n",
    "    ehr_model = ehr_model.cuda() \n",
    "#model optimizers to choose from. Upper/lower case dont matter\n",
    "if args.optimizer.lower() == 'adam':\n",
    "    optimizer = optim.Adam(ehr_model.parameters(), \n",
    "                           lr=args.lr, \n",
    "                           weight_decay=args.L2)\n",
    "elif args.optimizer.lower() == 'adadelta':\n",
    "    optimizer = optim.Adadelta(ehr_model.parameters(), \n",
    "                               lr=args.lr, \n",
    "                               weight_decay=args.L2)\n",
    "elif args.optimizer.lower() == 'adagrad':\n",
    "    optimizer = optim.Adagrad(ehr_model.parameters(), \n",
    "                              lr=args.lr, \n",
    "                              weight_decay=args.L2) \n",
    "elif args.optimizer.lower() == 'adamax':\n",
    "    optimizer = optim.Adamax(ehr_model.parameters(), \n",
    "                             lr=args.lr, \n",
    "                             weight_decay=args.L2)\n",
    "elif args.optimizer.lower() == 'asgd':\n",
    "    optimizer = optim.ASGD(ehr_model.parameters(), \n",
    "                           lr=args.lr, \n",
    "                           weight_decay=args.L2)\n",
    "elif args.optimizer.lower() == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(ehr_model.parameters(), \n",
    "                              lr=args.lr, \n",
    "                              weight_decay=args.L2)\n",
    "elif args.optimizer.lower() == 'rprop':\n",
    "    optimizer = optim.Rprop(ehr_model.parameters(), \n",
    "                            lr=args.lr)\n",
    "elif args.optimizer.lower() == 'sgd':\n",
    "    optimizer = optim.SGD(ehr_model.parameters(), \n",
    "                          lr=args.lr, \n",
    "                          weight_decay=args.L2)\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. Train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Current running on Epoch (0), Average_loss (0.42608730097611747)\u001b[0m\n",
      "\u001b[32mTrain_auc (0.6913143931598248), Valid_auc (0.6145069648093842)\u001b[0m\n",
      "\u001b[32mTrain_time (1m 7s), Valid_time (0m 3s)\u001b[0m\n",
      "\u001b[32m\n",
      "Current running on Epoch (1), Average_loss (0.3597108868757884)\u001b[0m\n",
      "\u001b[32mTrain_auc (0.7589733388285548), Valid_auc (0.6701910740469208)\u001b[0m\n",
      "\u001b[32mTrain_time (0m 58s), Valid_time (0m 3s)\u001b[0m\n",
      "\u001b[32m\n",
      "Current running on Epoch (2), Average_loss (0.33940000454584757)\u001b[0m\n",
      "\u001b[32mTrain_auc (0.8010523896013336), Valid_auc (0.7169240285923754)\u001b[0m\n",
      "\u001b[32mTrain_time (1m 0s), Valid_time (0m 6s)\u001b[0m\n",
      "\u001b[32m\n",
      "Current running on Epoch (3), Average_loss (0.32462459921836845)\u001b[0m\n",
      "\u001b[32mTrain_auc (0.8278247528693398), Valid_auc (0.7545065065982405)\u001b[0m\n",
      "\u001b[32mTrain_time (1m 3s), Valid_time (0m 3s)\u001b[0m\n",
      "\u001b[32m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32mExiting from training early\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Notes: default: sort data based on visit length \n",
    "#default: （batch）shuffle = true\n",
    "#allows for keyboard interrupt\n",
    "#saving best model in the directory specified in args.output_dir\n",
    "try:\n",
    "    ut.epochs_run(args.epochs, \n",
    "                  train = trainloader, \n",
    "                  valid = validloader, \n",
    "                  test = testloader, \n",
    "                  model = ehr_model, \n",
    "                  optimizer = optimizer,\n",
    "                  shuffle = True, \n",
    "                  batch_size = args.batch_size, \n",
    "                  which_model = args.which_model, \n",
    "                  patience = args.patience,\n",
    "                  output_dir = args.output_dir)\n",
    "#we can keyboard interupt now \n",
    "except KeyboardInterrupt:\n",
    "    print(colored('-' * 89, 'green'))\n",
    "    print(colored('Exiting from training early','green'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EHR_RNN(\n",
       "  (embed): Embedding(15817, 256, padding_idx=0)\n",
       "  (rnn_c): GRU(256, 256, dropout=0.1, bidirectional=1)\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you want to use previous trained models, use\n",
    "best_model= torch.load(args.output_dir + 'EHRmodel.pth')\n",
    "best_model.load_state_dict(torch.load(args.output_dir + 'EHRmodel.st'))\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StepExtra: Singly use our dataloader for data preparation purposes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EHRDataloader import EHRdataFromPickles, EHRdataloader, iter_batch2\n",
    "data2 = EHRdataFromPickles(root_dir = args.root_dir, \n",
    "                          file = args.file, \n",
    "                          sort= False,\n",
    "                          test_ratio = args.test_ratio, \n",
    "                          valid_ratio = args.valid_ratio) \n",
    "loader2 =  EHRdataloader(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to shuffle batches before using them, add this line \n",
    "#(options are achieved in utils by setting shuffle = True)\n",
    "loader2 = iter_batch2(loader = loader2, len(loader2))\n",
    "\n",
    "#otherwise, directly call \n",
    "for i, batch in enumerate(loader2): \n",
    "    #feed the batch to do things"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
