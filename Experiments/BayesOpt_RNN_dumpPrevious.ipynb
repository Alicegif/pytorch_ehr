{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook is to demonstrate how to use Bayesian Optimization package on github <https://github.com/fmfn/BayesianOptimization> locally to tune hyperparamters for our models(RNN only) for predicting heart failure onset risk on cerner sample data\n",
    "* For this demonstration, the data is the original 1 hospital (h143) previously used by retain, with 42,729 patients in total\n",
    "* The hyperparameters to be tuned are: learning rate, l2 regularization, and eps for optimizer, dropout rate, embedding dimension, hidden dimension, number of layers and optimizer\n",
    "* To implement this, first you need to install the package: however we modify the package file a bit to bypass errors and keep on iterating. The modified files could be found at Experiments/modifiedBO\n",
    "* Then **important**: you need to define a function (in our case model_tune()) which takes in the hyperparameters: l2_exp, lr_exp, eps_exp on logscale, embed_dim, hid_dim on log2scale, dropout and also ct_code, dlm_code and opt_code, and run the model using models, Loaddata, and TrainVaTe modules and return the best validation auc. We put the categorical parameters: ct_code: cell_type code which includes RNN, GRU and LSTM; dlm_code: model code which includes RNN and DRNN, and opt_code: optimitzer code which includes 7 optimizers to a 3-level loop so that each time we run BO, it takes a combination of model, cell_type and optimizer and return the rest of best parameters based on best validation auc\n",
    "* Be ware that this BO package will search float parameters, so if you have int or categorical parameters you want to tune, you might want to transform those values in your function before giving those to your models (like we did here)\n",
    "* Then **important**: call BO function and pass your model_tune(), a search range for each parameter ((-16, 1) means -16 and 1 inclusive), and give it points to explore (points that will give you large target values) if you want to, and call maximize() and pass number of iterations you want to run BO\n",
    "* Then **important**: if you have an unreliable GPU as we do, you might want to dump previously searched results back to your BO function so that it won't explore those spaces as again. We do that by importing previous searched results stored in 'BORNN_Init.csv' as a dataframe, and call initialize_df() for the Bo object\n",
    "* Then you will get results of your initial designated explored points(if any), 5 system initializations + previously searched results, and plus number of BO iterations\n",
    "* For our results:it's time consuming for RNN model, but it improved our best validation auc **from 0.65057** to currently **0.72976**\n",
    "\n",
    " Bayesian Optimization\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "Step |   Time |      Value |   dropout |   embdim_exp |   eps_exp |   hid_exp |    l2_exp |   layers_n |    lr_exp |\n",
    " \n",
    "56 | 00m00s |    0.72976 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -3.8164 |     2.0000 |   -5.1497 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_RNN as model #this changed\n",
    "import Loaddata_final as Loaddata\n",
    "import TrVaTe as TVT #This changed \n",
    "\n",
    "# check GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing data...\n",
      "\n",
      "Sample data after split:\n",
      "[0, [[1667, 144, 62, 85], [1667, 144, 62, 85]]]\n",
      "model is RNN\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "set_x = pickle.load(open('Data/h143.visits', 'rb'), encoding='bytes')\n",
    "set_y = pickle.load(open('Data/h143.labels', 'rb'),encoding='bytes')\n",
    "\n",
    "\"\"\"\n",
    "model_x = []\n",
    "for patient in set_x:\n",
    "    model_x.append([each for visit in patient for each in visit])  \n",
    "    \n",
    "\"\"\"\n",
    "model_x = set_x  #this is for the rest of the models\n",
    "    \n",
    "merged_set= [[set_y[i],model_x[i]] for i in range(len(set_y))] #list of list or list of lists of lists\n",
    "print(\"\\nLoading and preparing data...\")    \n",
    "train1, valid1, test1 = Loaddata.load_data(merged_set)\n",
    "print(\"\\nSample data after split:\")  \n",
    "print(train1[0])\n",
    "print(\"model is\", 'RNN') #can change afterwards, currently on most basic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print2file(buf, outFile):\n",
    "    outfd = open(outFile, 'a')\n",
    "    outfd.write(buf + '\\n')\n",
    "    outfd.close()\n",
    "\n",
    "logFile='JustRNN.log'\n",
    "header = 'Model|EmbSize|CellType|n_Layers|Hidden|Dropout|Optimizer|LR|L2|EPs|BestValidAUC|TestAUC|atEpoch'\n",
    "print2file(header, logFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on RNN with celltype plain RNN, adamax \n",
    "def model_tune(embdim_exp, hid_exp, layers_n, dropout, l2_exp , lr_exp, eps_exp):\n",
    "    #little transformations to use the searched values\n",
    "    embed_dim = 2** int(embdim_exp)\n",
    "    hidden_size = 2** int(hid_exp)\n",
    "    n_layers = int(layers_n)\n",
    "    dropout = round(dropout, 4)\n",
    "    l2 = np.exp(l2_exp)\n",
    "    lr = np.exp(lr_exp)\n",
    "    eps = np.exp(eps_exp)\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "   #dealing with categorical data\n",
    "    if int(dlm_code)<3:\n",
    "      if int(ct_code) ==1:\n",
    "          cell_type='RNN'   \n",
    "      elif int(ct_code) ==2:\n",
    "          cell_type='LSTM'\n",
    "      elif int(ct_code) ==3:\n",
    "          cell_type='GRU'\n",
    "      \n",
    "    if int(dlm_code)==1:\n",
    "        w_model='RNN'\n",
    "        ehr_model = model.EHR_RNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type)\n",
    "    elif int(dlm_code)==2:\n",
    "        w_model='DRNN'\n",
    "        ehr_model = model.DRNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type)\n",
    "\n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda(0)    \n",
    "        \n",
    "        \n",
    "    if int(opt_code) ==1:\n",
    "        opt= 'Adadelta'\n",
    "        optimizer = optim.Adadelta(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps) ## rho=0.9\n",
    "    elif int(opt_code) ==2:\n",
    "        opt= 'Adagrad'\n",
    "        optimizer = optim.Adagrad(ehr_model.parameters(), lr=lr, weight_decay=l2) ##lr_decay no eps\n",
    "    elif int(opt_code) ==3:\n",
    "        opt= 'Adam'\n",
    "        optimizer = optim.Adam(ehr_model.parameters(), lr=lr, weight_decay=l2,eps=eps ) ## Beta defaults (0.9, 0.999), amsgrad (false)\n",
    "    elif int(opt_code) ==4:\n",
    "        opt= 'Adamax'\n",
    "        optimizer = optim.Adamax(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps) ### Beta defaults (0.9, 0.999)\n",
    "    elif int(opt_code) ==5:\n",
    "        opt= 'RMSprop'\n",
    "        optimizer = optim.RMSprop(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps)                \n",
    "    elif int(opt_code) ==6:\n",
    "        opt= 'ASGD'\n",
    "        optimizer = optim.ASGD(ehr_model.parameters(), lr=lr, weight_decay=l2 ) ### other parameters\n",
    "    elif int(opt_code) ==7:\n",
    "        opt= 'SGD'\n",
    "        optimizer = optim.SGD(ehr_model.parameters(), lr=lr, weight_decay=l2 ) ### other parameters\n",
    "  \n",
    "    \"\"\"\n",
    "    ehr_model = model.EHR_RNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type = 'RNN')\n",
    "\n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda(0)    \n",
    "    optimizer = optim.Adamax(ehr_model.parameters(), lr=lr, weight_decay=l2,eps=eps)         \n",
    "\n",
    "     \n",
    "    bestValidAuc = 0.0\n",
    "    bestTestAuc = 0.0\n",
    "    bestValidEpoch = 0\n",
    "  \n",
    "    for ep in range(epochs):\n",
    "        current_loss, train_loss = TVT.train(train1, model= ehr_model, optimizer = optimizer, batch_size = 200)\n",
    "        avg_loss = np.mean(train_loss)\n",
    "        valid_auc, y_real, y_hat  = TVT.calculate_auc(model = ehr_model, data = valid1, which_model = 'RNN', batch_size = 200)\n",
    "        if valid_auc > bestValidAuc: \n",
    "            bestValidAuc = valid_auc\n",
    "            bestValidEpoch = ep\n",
    "            best_model= ehr_model\n",
    "            #bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = ehr_model, data = test1, which_model = w_model, batch_size = 200)\n",
    "\n",
    "        if ep - bestValidEpoch > 12:\n",
    "            break\n",
    "      \n",
    "  \n",
    "     \n",
    "    fname= 'RNN'+'E'+str(embed_dim)+'RNN'+'L'+str(n_layers)+'H'+str(hidden_size)+'D'+str(dropout)+'Adamax'+'L'+str(lr)+'P'+str(l2)  \n",
    "    bmodel_pth='models/'+fname\n",
    "    bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = best_model, data = test1, which_model = 'RNN', batch_size = 200)\n",
    "    torch.save(best_model, bmodel_pth)\n",
    "    buf = '|%f |%f |%d ' % (bestValidAuc, bestTestAuc, bestValidEpoch )\n",
    "    \n",
    "    pFile= 'RNN'+'|'+str(embdim_exp)+'|'+'RNN'+'|'+str(layers_n)+'|'+str(hid_exp)+'|'+str(dropout)+'|'+'Adamax'+'|'+str(lr_exp)+'|'+str(l2_exp)+'|'+str(eps_exp)+ buf  \n",
    "    print2file(pFile, logFile)\n",
    "    \n",
    "    return bestValidAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['target', 'embdim_exp', 'hid_exp', 'layers_n', 'dropout', 'l2_exp',\n",
      "       'lr_exp', 'eps_exp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>embdim_exp</th>\n",
       "      <th>hid_exp</th>\n",
       "      <th>layers_n</th>\n",
       "      <th>dropout</th>\n",
       "      <th>l2_exp</th>\n",
       "      <th>lr_exp</th>\n",
       "      <th>eps_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675914</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.665504</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>-5.052670</td>\n",
       "      <td>-4.886371</td>\n",
       "      <td>-5.882410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.695596</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>-3.518894</td>\n",
       "      <td>-4.147615</td>\n",
       "      <td>-5.483880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555088</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>-1.362262</td>\n",
       "      <td>-2.489984</td>\n",
       "      <td>-8.804755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495318</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>-1.706429</td>\n",
       "      <td>-2.728325</td>\n",
       "      <td>-5.999451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  embdim_exp  hid_exp  layers_n  dropout    l2_exp    lr_exp  \\\n",
       "0  0.675914         8.0      8.0       1.0   0.1000 -3.000000 -3.000000   \n",
       "1  0.665504         5.0      6.0       1.0   0.1136 -5.052670 -4.886371   \n",
       "2  0.695596         8.0      5.0       1.0   0.2724 -3.518894 -4.147615   \n",
       "3  0.555088         6.0      8.0       1.0   0.6600 -1.362262 -2.489984   \n",
       "4  0.495318         6.0      7.0       2.0   0.0607 -1.706429 -2.728325   \n",
       "\n",
       "    eps_exp  \n",
       "0 -6.000000  \n",
       "1 -5.882410  \n",
       "2 -5.483880  \n",
       "3 -8.804755  \n",
       "4 -5.999451  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_df = pd.read_csv('BORNN_Init.csv' )\n",
    "print(init_df.columns)\n",
    "init_df.embdim_exp =np.log2(init_df.embdim_exp)\n",
    "init_df.hid_exp = np.log2(init_df.hid_exp)\n",
    "init_df.layers_n = init_df.layers_n.astype('float')\n",
    "init_df.l2_exp = np.log(init_df.l2_exp)\n",
    "init_df.lr_exp = np.log(init_df.lr_exp)\n",
    "init_df.eps_exp = np.log(init_df.eps_exp)\n",
    "init_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   dropout |   embdim_exp |   eps_exp |   hid_exp |    l2_exp |   layers_n |    lr_exp | \n",
      "    1 | 11m51s | \u001b[35m   0.65057\u001b[0m | \u001b[32m   0.1000\u001b[0m | \u001b[32m      8.0000\u001b[0m | \u001b[32m  -6.0000\u001b[0m | \u001b[32m   8.0000\u001b[0m | \u001b[32m  -3.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -3.0000\u001b[0m | \n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   dropout |   embdim_exp |   eps_exp |   hid_exp |    l2_exp |   layers_n |    lr_exp | \n",
      "    2 | 10m48s |    0.53969 |    0.8738 |       5.7305 |   -5.1428 |    7.6278 |   -1.7097 |     1.3937 |   -2.3070 | \n",
      "    3 | 10m33s |    0.58751 |    0.5243 |       5.2544 |   -8.6173 |    8.6280 |   -2.2143 |     1.1681 |   -6.4372 | \n",
      "    4 | 12m02s |    0.59175 |    0.0118 |       8.4797 |   -6.6592 |    8.8715 |   -2.2138 |     2.1839 |   -5.2764 | \n",
      "    5 | 10m00s |    0.56103 |    0.2144 |       7.2279 |   -5.4970 |    8.8524 |   -1.0971 |     1.3397 |   -3.3920 | \n",
      "    6 | 12m52s |    0.57507 |    0.5722 |       7.8342 |   -7.4660 |    7.6417 |   -2.5027 |     2.5122 |   -5.5348 | \n",
      "    7 | 00m00s | \u001b[35m   0.67591\u001b[0m | \u001b[32m   0.1000\u001b[0m | \u001b[32m      8.0000\u001b[0m | \u001b[32m  -6.0000\u001b[0m | \u001b[32m   8.0000\u001b[0m | \u001b[32m  -3.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -3.0000\u001b[0m | \n",
      "    8 | 00m00s |    0.66550 |    0.1136 |       5.0000 |   -5.8824 |    6.0000 |   -5.0527 |     1.0000 |   -4.8864 | \n",
      "    9 | 00m00s | \u001b[35m   0.69560\u001b[0m | \u001b[32m   0.2724\u001b[0m | \u001b[32m      8.0000\u001b[0m | \u001b[32m  -5.4839\u001b[0m | \u001b[32m   5.0000\u001b[0m | \u001b[32m  -3.5189\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -4.1476\u001b[0m | \n",
      "   10 | 00m00s |    0.55509 |    0.6600 |       6.0000 |   -8.8048 |    8.0000 |   -1.3623 |     1.0000 |   -2.4900 | \n",
      "   11 | 00m00s |    0.49532 |    0.0607 |       6.0000 |   -5.9995 |    7.0000 |   -1.7064 |     2.0000 |   -2.7283 | \n",
      "   12 | 00m00s |    0.67572 |    0.5600 |       7.0000 |   -5.4677 |    8.0000 |   -4.8109 |     2.0000 |   -4.0957 | \n",
      "   13 | 00m00s | \u001b[35m   0.70270\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -9.0000\u001b[0m | \u001b[32m   5.0000\u001b[0m | \u001b[32m  -6.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -2.0000\u001b[0m | \n",
      "   14 | 00m00s | \u001b[35m   0.70711\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -9.0000\u001b[0m | \u001b[32m   9.0000\u001b[0m | \u001b[32m  -6.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -7.0000\u001b[0m | \n",
      "   15 | 00m00s |    0.60485 |    1.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "   16 | 00m00s |    0.62427 |    1.0000 |       9.0000 |   -9.0000 |    5.0000 |   -1.0000 |     1.0000 |   -7.0000 | \n",
      "   17 | 00m00s |    0.65911 |    1.0000 |       5.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   18 | 00m00s |    0.68523 |    1.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   19 | 00m00s |    0.63819 |    1.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "   20 | 00m00s |    0.66831 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   21 | 00m00s |    0.64010 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -1.0000 |     1.0000 |   -7.0000 | \n",
      "   22 | 00m00s |    0.66566 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -1.5413 |     1.0000 |   -7.0000 | \n",
      "   23 | 00m00s |    0.66951 |    0.0000 |       5.0000 |   -9.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   24 | 00m00s | \u001b[35m   0.71006\u001b[0m | \u001b[32m   1.0000\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -7.8027\u001b[0m | \u001b[32m   7.0000\u001b[0m | \u001b[32m  -4.8324\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -4.5382\u001b[0m | \n",
      "   25 | 00m00s |    0.48315 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -1.0000 |     1.0000 |   -2.0000 | \n",
      "   26 | 00m00s |    0.48462 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "   27 | 00m00s |    0.67548 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   28 | 00m00s |    0.47104 |    1.0000 |       5.0000 |   -5.0000 |    5.0000 |   -1.0000 |     1.0000 |   -7.0000 | \n",
      "   29 | 00m00s |    0.68137 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   30 | 00m00s | \u001b[35m   0.71496\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -5.0000\u001b[0m | \u001b[32m   9.0000\u001b[0m | \u001b[32m  -4.8759\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -7.0000\u001b[0m | \n",
      "   31 | 00m00s |    0.69114 |    1.0000 |       6.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -4.4628 | \n",
      "repeated\n",
      "   32 | 00m00s |    0.68351 |    0.1000 |       8.0000 |   -6.0000 |    8.0000 |   -3.0000 |     1.0000 |   -3.0000 | \n",
      "   33 | 00m00s |    0.61803 |    0.1848 |       6.0000 |   -5.4467 |    8.0000 |   -2.6906 |     2.0000 |   -2.5340 | \n",
      "   34 | 00m00s |    0.71341 |    0.0000 |       7.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -4.3184 | \n",
      "   35 | 00m00s |    0.68004 |    1.0000 |       7.0000 |   -7.4719 |    6.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   36 | 00m00s |    0.69973 |    0.1296 |       8.0000 |   -7.0451 |    5.0000 |   -3.6843 |     1.0000 |   -3.3325 | \n",
      "   37 | 00m00s |    0.70097 |    0.2091 |       8.0000 |   -7.8445 |    6.0000 |   -4.3187 |     1.0000 |   -5.2829 | \n",
      "   38 | 00m00s |    0.60014 |    0.9241 |       5.0000 |   -5.6211 |    6.0000 |   -4.7183 |     2.0000 |   -4.3673 | \n",
      "   39 | 00m00s |    0.68982 |    0.8935 |       8.0000 |   -5.9306 |    7.0000 |   -5.4853 |     1.0000 |   -3.6502 | \n",
      "   40 | 00m00s |    0.69424 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   41 | 00m00s |    0.60272 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "   42 | 00m00s |    0.47917 |    1.0000 |       9.0000 |   -9.0000 |    5.0000 |   -1.0000 |     1.0000 |   -2.0000 | \n",
      "repeated\n",
      "   43 | 00m00s |    0.65888 |    0.0000 |       5.0000 |   -9.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   44 | 00m00s | \u001b[35m   0.71765\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -9.0000\u001b[0m | \u001b[32m   9.0000\u001b[0m | \u001b[32m  -6.0000\u001b[0m | \u001b[32m    3.0000\u001b[0m | \u001b[32m  -7.0000\u001b[0m | \n",
      "   45 | 00m00s |    0.63941 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "   46 | 00m00s |    0.67794 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "   47 | 00m00s |    0.51846 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -1.0000 |     3.0000 |   -7.0000 | \n",
      "   48 | 00m00s |    0.70555 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -6.0000 |     3.0000 |   -4.3760 | \n",
      "   49 | 00m00s |    0.66655 |    0.0000 |       5.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   50 | 00m00s |    0.70940 |    0.0000 |       9.0000 |   -6.1734 |    9.0000 |   -6.0000 |     1.0000 |   -4.6288 | \n",
      "   51 | 00m00s |    0.67790 |    0.0000 |       6.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -3.5705 | \n",
      "   52 | 00m00s |    0.67763 |    0.0000 |       9.0000 |   -6.9767 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   53 | 00m00s |    0.71311 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -6.0652 | \n",
      "repeated\n",
      "   54 | 00m00s |    0.66806 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   55 | 00m00s |    0.70718 |    0.0000 |       9.0000 |   -7.3603 |    7.0000 |   -5.9601 |     2.0000 |   -4.3038 | \n",
      "   56 | 00m00s | \u001b[35m   0.72976\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -9.0000\u001b[0m | \u001b[32m   9.0000\u001b[0m | \u001b[32m  -3.8164\u001b[0m | \u001b[32m    2.0000\u001b[0m | \u001b[32m  -5.1497\u001b[0m | \n",
      "   57 | 00m00s |    0.59087 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -3.2837 |     1.0000 |   -3.1945 | \n",
      "   58 | 00m00s |    0.64631 |    0.0000 |       5.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   59 | 00m00s |    0.69876 |    0.0000 |       9.0000 |   -9.0000 |    8.0000 |   -3.9796 |     1.0000 |   -7.0000 | \n",
      "   60 | 00m00s |    0.72650 |    0.0000 |       9.0000 |   -9.0000 |    7.0000 |   -4.4355 |     2.0000 |   -5.4508 | \n",
      "   61 | 00m00s |    0.50000 |    1.0000 |       9.0000 |   -8.9713 |    9.0000 |   -5.1780 |     2.0000 |   -5.0566 | \n",
      "   62 | 00m00s |    0.67508 |    0.0000 |       6.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "   63 | 00m00s |    0.49490 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -1.0000 |     3.0000 |   -7.0000 | \n",
      "   64 | 00m00s |    0.50027 |    0.0000 |       6.0000 |   -9.0000 |    5.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "   65 | 00m00s |    0.69747 |    0.0000 |       6.0000 |   -5.0000 |    7.0000 |   -6.0000 |     1.0000 |   -4.2937 | \n",
      "   66 | 00m00s |    0.70250 |    0.0000 |       9.0000 |   -9.0000 |    6.0000 |   -4.0715 |     3.0000 |   -2.0000 | \n",
      "   67 | 00m00s |    0.70956 |    0.0000 |       9.0000 |   -9.0000 |    6.0000 |   -4.3093 |     1.0000 |   -3.5062 | \n",
      "   68 | 00m00s |    0.68050 |    0.0000 |       6.0000 |   -6.8668 |    6.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "   69 | 00m00s |    0.71190 |    0.0000 |       9.0000 |   -5.0000 |    6.0000 |   -4.2552 |     3.0000 |   -5.3179 | \n",
      "   70 | 00m00s |    0.68968 |    0.0000 |       7.0000 |   -6.9588 |    9.0000 |   -4.6945 |     1.0000 |   -5.7422 | \n",
      "   71 | 00m00s |    0.45933 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -1.0000 |     3.0000 |   -2.0000 | \n",
      "   72 | 00m00s |    0.47286 |    0.0000 |       5.0000 |   -5.0000 |    5.0000 |   -1.0000 |     1.0000 |   -2.0000 | \n",
      "repeated\n",
      "   73 | 00m00s |    0.65543 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   74 | 00m00s |    0.71403 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "   75 | 00m00s |    0.69131 |    0.0000 |       7.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -3.6562 | \n",
      "   76 | 00m00s |    0.70298 |    0.0000 |       9.0000 |   -5.0000 |    7.0000 |   -4.2014 |     1.0000 |   -4.2308 | \n",
      "   77 | 00m00s |    0.68698 |    0.0000 |       7.0000 |   -9.0000 |    6.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   78 | 00m00s |    0.70447 |    0.0000 |       9.0000 |   -6.9078 |    7.0000 |   -4.4083 |     2.0000 |   -4.0573 | \n",
      "   79 | 00m00s |    0.67495 |    1.0000 |       7.0000 |   -5.0000 |    5.0000 |   -4.5128 |     1.0000 |   -2.0000 | \n",
      "   80 | 00m00s |    0.70529 |    0.0000 |       8.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "   81 | 00m00s |    0.69383 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "   82 | 00m00s |    0.65402 |    0.0000 |       6.0000 |   -9.0000 |    5.0000 |   -3.9583 |     2.0000 |   -2.0000 | \n",
      "   83 | 00m00s |    0.66767 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -2.6774 |     3.0000 |   -2.3245 | \n",
      "   84 | 00m00s |    0.64496 |    0.0000 |       9.0000 |   -9.0000 |    6.0000 |   -6.0000 |     1.0000 |   -6.8591 | \n",
      "   85 | 00m00s |    0.71182 |    0.0000 |       9.0000 |   -6.3527 |    5.0000 |   -4.8290 |     3.0000 |   -4.4832 | \n",
      "   86 | 00m00s |    0.70034 |    0.0000 |       7.0000 |   -9.0000 |    8.0000 |   -5.1080 |     1.0000 |   -4.1230 | \n",
      "   87 | 00m00s |    0.68609 |    0.0000 |       6.0000 |   -6.5236 |    7.0000 |   -4.9372 |     1.0000 |   -3.3009 | \n",
      "   88 | 00m00s |    0.70652 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -4.0232 |     1.0000 |   -3.8546 | \n",
      "   89 | 00m00s |    0.67167 |    1.0000 |       6.0000 |   -5.0000 |    7.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "   90 | 00m00s |    0.67685 |    0.0000 |       5.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -5.5649 | \n",
      "   91 | 00m00s |    0.69684 |    0.0000 |       8.0000 |   -9.0000 |    7.0000 |   -3.1999 |     1.0000 |   -4.8256 | \n",
      "   92 | 00m00s |    0.70830 |    0.0000 |       7.0000 |   -5.0000 |    9.0000 |   -4.5482 |     1.0000 |   -4.7299 | \n",
      "   93 | 00m00s |    0.69383 |    0.0000 |       9.0000 |   -5.0000 |    7.0000 |   -6.0000 |     2.0000 |   -4.6739 | \n",
      "   94 | 00m00s |    0.70465 |    0.0000 |       8.0000 |   -7.5082 |    5.0000 |   -4.6009 |     3.0000 |   -3.7424 | \n",
      "   95 | 00m00s |    0.70475 |    0.0000 |       8.0000 |   -8.0689 |    9.0000 |   -4.4192 |     2.0000 |   -6.6550 | \n",
      "   96 | 00m00s |    0.68469 |    0.0000 |       8.0000 |   -5.0000 |    5.0000 |   -3.0637 |     1.0000 |   -4.7724 | \n",
      "   97 | 00m00s |    0.70489 |    0.0040 |       8.0000 |   -8.7446 |    6.0000 |   -5.1195 |     2.0000 |   -3.6824 | \n",
      "   98 | 00m00s |    0.71379 |    0.0000 |       9.0000 |   -7.0333 |    6.0000 |   -3.6739 |     2.0000 |   -5.4559 | \n",
      "   99 | 00m00s |    0.68407 |    0.0000 |       7.0000 |   -5.0465 |    6.0000 |   -3.9594 |     1.0000 |   -4.4853 | \n",
      "  100 | 00m00s |    0.69654 |    0.0000 |       6.0000 |   -6.8062 |    9.0000 |   -6.0000 |     1.0000 |   -4.1771 | \n",
      "  101 | 00m00s |    0.72353 |    0.0000 |       9.0000 |   -8.3084 |    9.0000 |   -4.8772 |     1.0000 |   -5.8647 | \n",
      "  102 | 00m00s |    0.71737 |    0.0000 |       9.0000 |   -6.1308 |    8.0000 |   -4.9451 |     1.0000 |   -5.7862 | \n",
      "  103 | 00m00s |    0.72234 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -4.7677 |     1.0000 |   -6.5276 | \n",
      "  104 | 00m00s |    0.71124 |    0.0000 |       8.0000 |   -8.3212 |    7.0000 |   -4.3012 |     1.0000 |   -4.8196 | \n",
      "  105 | 00m00s |    0.72257 |    0.0000 |       9.0000 |   -5.6930 |    9.0000 |   -4.5624 |     2.0000 |   -5.3360 | \n",
      "  106 | 00m00s |    0.70068 |    0.0000 |       8.0000 |   -5.0000 |    8.0000 |   -4.7571 |     1.0000 |   -4.4951 | \n",
      "  107 | 00m00s |    0.72706 |    0.0000 |       8.0000 |   -6.7448 |    9.0000 |   -6.0000 |     3.0000 |   -5.6509 | \n",
      "  108 | 00m00s |    0.72252 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -6.0168 | \n",
      "  109 | 00m00s |    0.69989 |    0.0000 |       8.0000 |   -7.4178 |    6.0000 |   -4.4754 |     3.0000 |   -4.7496 | \n",
      "  110 | 00m00s |    0.71522 |    0.0000 |       9.0000 |   -7.3239 |    8.0000 |   -4.5004 |     1.0000 |   -4.8335 | \n",
      "  111 | 00m00s |    0.70397 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  112 | 00m00s |    0.69944 |    0.0000 |       9.0000 |   -5.7352 |    8.0000 |   -4.9888 |     2.0000 |   -6.5413 | \n",
      "  113 | 00m00s |    0.70136 |    0.0000 |       8.0000 |   -9.0000 |    8.0000 |   -6.0000 |     2.0000 |   -5.5794 | \n",
      "  114 | 00m00s |    0.70010 |    0.0000 |       8.0000 |   -9.0000 |    5.0000 |   -4.6989 |     1.0000 |   -2.0000 | \n",
      "  115 | 00m00s |    0.69708 |    0.0000 |       8.0000 |   -5.2266 |    6.0000 |   -4.9730 |     2.0000 |   -2.0000 | \n",
      "  116 | 00m00s |    0.70724 |    0.0036 |       8.0000 |   -5.5617 |    8.0000 |   -5.5208 |     2.0000 |   -5.7252 | \n",
      "  117 | 00m00s |    0.70794 |    0.0000 |       8.0000 |   -6.7521 |    5.0000 |   -4.3091 |     1.0000 |   -4.3192 | \n",
      "  118 | 00m00s |    0.69743 |    0.0000 |       8.0000 |   -6.6894 |    8.0000 |   -4.7293 |     2.0000 |   -3.2660 | \n",
      "  119 | 00m00s |    0.70712 |    0.0000 |       8.0000 |   -6.2201 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "  120 | 00m00s |    0.69500 |    0.0000 |       8.0000 |   -6.6500 |    7.0000 |   -3.7811 |     1.0000 |   -5.1647 | \n",
      "  121 | 00m00s |    0.71675 |    0.0000 |       8.0000 |   -9.0000 |    5.0000 |   -4.5034 |     1.0000 |   -4.0763 | \n",
      "repeated\n",
      "  122 | 00m00s |    0.67888 |    0.1000 |       8.0000 |   -6.0000 |    8.0000 |   -3.0000 |     1.0000 |   -3.0000 | \n",
      "  123 | 00m00s |    0.49066 |    0.3024 |       6.0000 |   -7.6030 |    8.0000 |   -1.1415 |     2.0000 |   -5.3487 | \n",
      "  124 | 00m00s |    0.64390 |    0.2482 |       5.0000 |   -5.0356 |    6.0000 |   -3.8050 |     1.0000 |   -6.7213 | \n",
      "  125 | 00m00s |    0.61786 |    0.6830 |       5.0000 |   -6.6281 |    8.0000 |   -4.5281 |     2.0000 |   -6.0868 | \n",
      "  126 | 00m00s |    0.52525 |    0.9915 |       8.0000 |   -7.4302 |    5.0000 |   -5.8423 |     2.0000 |   -6.0236 | \n",
      "  127 | 00m00s |    0.67708 |    0.7178 |       8.0000 |   -8.5257 |    8.0000 |   -5.3145 |     2.0000 |   -5.9980 | \n",
      "repeated\n",
      "  128 | 00m00s |    0.69492 |    0.1000 |       8.0000 |   -6.0000 |    8.0000 |   -3.0000 |     1.0000 |   -3.0000 | \n",
      "  129 | 00m00s |    0.64548 |    0.3814 |       8.0000 |   -5.4082 |    6.0000 |   -1.6340 |     1.0000 |   -6.7550 | \n",
      "  130 | 00m00s |    0.66374 |    0.4088 |       5.0000 |   -8.1060 |    6.0000 |   -4.1567 |     2.0000 |   -4.8190 | \n",
      "  131 | 00m00s |    0.63225 |    0.9766 |       5.0000 |   -6.0877 |    7.0000 |   -4.0175 |     1.0000 |   -5.8779 | \n",
      "  132 | 00m00s |    0.53179 |    0.9049 |       7.0000 |   -7.5523 |    5.0000 |   -1.1900 |     1.0000 |   -3.1424 | \n",
      "  133 | 00m00s |    0.69613 |    0.2880 |       8.0000 |   -5.7442 |    7.0000 |   -5.7534 |     1.0000 |   -2.2276 | \n",
      "repeated\n",
      "  134 | 00m00s |    0.70814 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "repeated\n",
      "  135 | 00m00s |    0.67414 |    0.1000 |       8.0000 |   -6.0000 |    8.0000 |   -3.0000 |     1.0000 |   -3.0000 | \n",
      "  136 | 00m00s |    0.61278 |    0.0001 |       5.0000 |   -7.0351 |    6.0000 |   -2.8426 |     1.0000 |   -6.8576 | \n",
      "  137 | 00m00s |    0.67055 |    0.5291 |       7.0000 |   -8.2068 |    5.0000 |   -3.4709 |     1.0000 |   -3.3319 | \n",
      "  138 | 00m00s |    0.68073 |    0.3904 |       7.0000 |   -6.1834 |    5.0000 |   -5.2645 |     1.0000 |   -3.2080 | \n",
      "  139 | 00m00s |    0.65180 |    0.1998 |       7.0000 |   -6.1802 |    6.0000 |   -2.5097 |     1.0000 |   -3.2534 | \n",
      "  140 | 00m00s |    0.63695 |    0.5356 |       6.0000 |   -6.7165 |    5.0000 |   -4.9935 |     2.0000 |   -2.9571 | \n",
      "  141 | 00m00s |    0.50000 |    1.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "  142 | 00m00s |    0.63562 |    1.0000 |       9.0000 |   -5.0000 |    5.0000 |   -1.0000 |     1.0000 |   -7.0000 | \n",
      "repeated\n",
      "  143 | 00m00s |    0.68805 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  144 | 00m00s |    0.47138 |    1.0000 |       5.0000 |   -9.0000 |    5.0000 |   -1.0000 |     1.0000 |   -2.0000 | \n",
      "repeated\n",
      "  145 | 00m00s |    0.62194 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "  146 | 00m00s |    0.69292 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "repeated\n",
      "  147 | 00m00s |    0.50400 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -1.0000 |     3.0000 |   -7.0000 | \n",
      "repeated\n",
      "  148 | 00m00s |    0.68732 |    1.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  149 | 00m00s |    0.67377 |    1.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  150 | 00m00s |    0.62330 |    1.0000 |       5.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "  151 | 00m00s |    0.50000 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -1.0000 |     3.0000 |   -2.0000 | \n",
      "repeated\n",
      "  152 | 00m00s |    0.66144 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "repeated\n",
      "  153 | 00m00s |    0.67087 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  154 | 00m00s |    0.70856 |    0.0000 |       9.0000 |   -9.0000 |    8.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  155 | 00m00s |    0.52169 |    0.0000 |       5.0000 |   -5.0000 |    9.0000 |   -1.0000 |     1.0000 |   -7.0000 | \n",
      "  156 | 00m00s |    0.68388 |    0.0000 |       9.0000 |   -6.3695 |    5.0000 |   -3.1415 |     1.0000 |   -2.0000 | \n",
      "  157 | 00m00s |    0.69864 |    0.0000 |       9.0000 |   -9.0000 |    7.0000 |   -3.9429 |     1.0000 |   -2.0000 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  158 | 00m00s |    0.68370 |    0.0000 |       5.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  159 | 00m00s |    0.69418 |    0.0000 |       7.0000 |   -7.6238 |    8.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  160 | 00m00s |    0.68251 |    0.0000 |       9.0000 |   -7.1880 |    7.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  161 | 00m00s |    0.66369 |    0.0000 |       5.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -5.2222 | \n",
      "  162 | 00m00s |    0.68654 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -3.5124 |     1.0000 |   -4.4816 | \n",
      "repeated\n",
      "  163 | 00m00s |    0.66871 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  164 | 00m00s |    0.50000 |    1.0000 |       9.0000 |   -9.0000 |    6.0000 |   -5.2685 |     3.0000 |   -2.0000 | \n",
      "  165 | 00m00s |    0.63979 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -1.0000 |     1.0000 |   -5.8840 | \n",
      "  166 | 00m00s |    0.60108 |    0.0000 |       6.0000 |   -9.0000 |    5.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "  167 | 00m00s |    0.71172 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -4.3408 | \n",
      "  168 | 00m00s |    0.67734 |    0.0000 |       5.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -5.9489 | \n",
      "  169 | 00m00s |    0.53964 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -1.0000 |     1.0000 |   -4.0521 | \n",
      "  170 | 00m00s |    0.65532 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -2.4423 |     3.0000 |   -7.0000 | \n",
      "  171 | 00m00s |    0.66448 |    0.0000 |       6.0000 |   -5.0000 |    5.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  172 | 00m00s |    0.50000 |    1.0000 |       5.0000 |   -5.0000 |    5.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "  173 | 00m00s |    0.59106 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -2.8594 |     3.0000 |   -4.6338 | \n",
      "repeated\n",
      "  174 | 00m00s |    0.69876 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  175 | 00m00s |    0.67666 |    0.0000 |       5.0000 |   -9.0000 |    5.0000 |   -6.0000 |     1.0000 |   -3.1772 | \n",
      "  176 | 00m00s |    0.71368 |    0.0000 |       9.0000 |   -7.6994 |    9.0000 |   -4.0015 |     2.0000 |   -4.0781 | \n",
      "  177 | 00m00s |    0.71793 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -3.7994 |     1.0000 |   -5.9334 | \n",
      "  178 | 00m00s |    0.71991 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -5.1140 | \n",
      "  179 | 00m00s |    0.70802 |    0.0000 |       7.0000 |   -9.0000 |    9.0000 |   -4.0730 |     1.0000 |   -4.5210 | \n",
      "  180 | 00m00s |    0.69639 |    0.0000 |       7.0000 |   -7.7014 |    5.0000 |   -4.2857 |     1.0000 |   -4.2394 | \n",
      "  181 | 00m00s |    0.68423 |    1.0000 |       5.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -3.6760 | \n",
      "  182 | 00m00s |    0.71001 |    0.0000 |       7.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -5.0207 | \n",
      "  183 | 00m00s |    0.71392 |    0.0000 |       9.0000 |   -6.9567 |    9.0000 |   -3.9409 |     1.0000 |   -5.5775 | \n",
      "  184 | 00m00s |    0.71326 |    0.0000 |       7.0000 |   -5.0000 |    9.0000 |   -5.0606 |     3.0000 |   -4.2626 | \n",
      "repeated\n",
      "  185 | 00m00s |    0.63390 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -1.0000 |     1.0000 |   -7.0000 | \n",
      "  186 | 00m00s |    0.70875 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -4.5530 | \n",
      "  187 | 00m00s |    0.71272 |    0.0000 |       7.0000 |   -7.3897 |    9.0000 |   -6.0000 |     2.0000 |   -3.9884 | \n",
      "  188 | 00m00s |    0.70489 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -4.4459 |     1.0000 |   -3.4071 | \n",
      "  189 | 00m00s |    0.67925 |    0.0000 |       6.0000 |   -9.0000 |    6.0000 |   -5.4182 |     1.0000 |   -3.8286 | \n",
      "  190 | 00m00s |    0.68074 |    1.0000 |       7.0000 |   -7.0439 |    9.0000 |   -3.1206 |     1.0000 |   -5.1356 | \n",
      "  191 | 00m00s |    0.69956 |    0.0000 |       8.0000 |   -5.0000 |    7.0000 |   -4.2148 |     1.0000 |   -5.0667 | \n",
      "  192 | 00m00s |    0.71363 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "  193 | 00m00s |    0.71315 |    0.0000 |       9.0000 |   -5.0729 |    9.0000 |   -4.0281 |     1.0000 |   -7.0000 | \n",
      "  194 | 00m00s |    0.70908 |    0.0000 |       9.0000 |   -6.2446 |    9.0000 |   -4.6009 |     1.0000 |   -3.8256 | \n",
      "  195 | 00m00s |    0.69283 |    0.0000 |       9.0000 |   -6.2453 |    5.0000 |   -6.0000 |     1.0000 |   -3.1902 | \n",
      "  196 | 00m00s |    0.67359 |    0.0000 |       5.0000 |   -7.0260 |    9.0000 |   -6.0000 |     1.0000 |   -4.6645 | \n",
      "  197 | 00m00s |    0.72120 |    0.0000 |       8.0000 |   -5.0000 |    9.0000 |   -6.0000 |     3.0000 |   -4.1409 | \n",
      "  198 | 00m00s |    0.70759 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -2.7378 | \n",
      "  199 | 00m00s |    0.68831 |    0.0000 |       6.0000 |   -5.0000 |    9.0000 |   -6.0000 |     2.0000 |   -3.9277 | \n",
      "  200 | 00m00s |    0.71260 |    0.0000 |       8.0000 |   -5.0000 |    8.0000 |   -5.0669 |     1.0000 |   -5.2225 | \n",
      "  201 | 00m00s |    0.71732 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n",
      "  202 | 00m00s |    0.67067 |    0.0000 |       7.0000 |   -9.0000 |    9.0000 |   -3.7543 |     1.0000 |   -2.0913 | \n",
      "  203 | 00m00s |    0.70640 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -3.5357 |     1.0000 |   -7.0000 | \n",
      "  204 | 00m00s |    0.70561 |    0.0000 |       9.0000 |   -6.7454 |    7.0000 |   -3.2950 |     1.0000 |   -6.7314 | \n",
      "  205 | 00m00s |    0.61267 |    0.0000 |       5.0000 |   -5.0000 |    5.0000 |   -3.6817 |     1.0000 |   -2.0000 | \n",
      "  206 | 00m00s |    0.70712 |    0.0000 |       8.0000 |   -7.0516 |    9.0000 |   -4.7905 |     1.0000 |   -7.0000 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   dropout |   embdim_exp |   eps_exp |   hid_exp |    l2_exp |   layers_n |    lr_exp | \n",
      "  207 | 10m00s |    0.61580 |    0.5438 |       8.6761 |   -5.0000 |    9.0000 |   -2.5734 |     1.0000 |   -2.0636 | \n",
      "  208 | 18m53s |    0.68049 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -4.7928 |     3.0000 |   -4.0226 | \n",
      "  209 | 37m30s |    0.71544 |    0.8989 |       8.4411 |   -5.0387 |    6.4137 |   -3.4640 |     1.0597 |   -6.9821 | \n",
      "  210 | 15m34s |    0.61446 |    1.0000 |       5.0000 |   -9.0000 |    5.0000 |   -3.3129 |     1.0000 |   -6.3220 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 48, 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00014627]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  211 | 10m07s |    0.64592 |    1.0000 |       6.7880 |   -6.5072 |    9.0000 |   -3.6473 |     1.0000 |   -2.0000 | \n",
      "  212 | 19m04s |    0.70695 |    0.0052 |       8.6842 |   -8.8354 |    7.8937 |   -5.1064 |     2.9930 |   -5.5228 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 47, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00032569]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  213 | 14m47s |    0.64576 |    0.0000 |       9.0000 |   -7.8240 |    5.1383 |   -3.8483 |     3.0000 |   -3.4143 | \n",
      "  214 | 16m09s |    0.70067 |    0.0029 |       8.9245 |   -7.4867 |    8.4109 |   -5.7601 |     2.5142 |   -6.1795 | \n",
      "  215 | 27m44s |    0.71237 |    0.9757 |       8.9788 |   -5.4152 |    6.9678 |   -3.8709 |     1.0090 |   -5.5277 | \n",
      "  216 | 35m51s |    0.70096 |    0.0000 |       7.5530 |   -5.0015 |    9.0000 |   -4.6321 |     2.9837 |   -6.3059 | \n",
      "  217 | 33m02s |    0.70091 |    0.0372 |       6.7867 |   -8.1661 |    8.8572 |   -5.2830 |     2.8349 |   -5.9943 | \n",
      "  218 | 12m30s |    0.61906 |    0.0000 |       5.0000 |   -9.0000 |    5.0238 |   -5.8791 |     3.0000 |   -2.0000 | \n",
      "  219 | 16m42s |    0.69518 |    0.0000 |       8.9808 |   -8.4012 |    6.8287 |   -5.6320 |     1.0000 |   -5.0292 | \n",
      "  220 | 16m29s |    0.66482 |    0.0000 |       9.0000 |   -6.5941 |    9.0000 |   -6.0000 |     3.0000 |   -2.6356 | \n",
      "  221 | 16m04s |    0.70742 |    0.8628 |       9.0000 |   -5.0661 |    5.0000 |   -3.4320 |     1.0423 |   -7.0000 | \n",
      "  222 | 22m33s |    0.67684 |    1.0000 |       7.0442 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  223 | 15m51s |    0.67334 |    0.0026 |       7.5389 |   -8.9399 |    7.6238 |   -4.5568 |     2.9172 |   -4.4362 | \n",
      "  224 | 19m11s |    0.70909 |    0.8835 |       8.7166 |   -5.0598 |    8.7691 |   -4.5603 |     1.0195 |   -6.8780 | \n",
      "  225 | 33m34s |    0.71473 |    0.0000 |       9.0000 |   -5.0000 |    5.2217 |   -3.4431 |     3.0000 |   -7.0000 | \n",
      "  226 | 12m17s |    0.69253 |    0.0126 |       7.3306 |   -5.0160 |    5.6324 |   -4.4789 |     2.9379 |   -5.6127 | \n",
      "  227 | 29m23s |    0.71270 |    0.0049 |       8.3601 |   -5.0203 |    6.6714 |   -3.8335 |     2.9907 |   -6.9764 | \n",
      "  228 | 15m05s |    0.70286 |    0.0000 |       7.3326 |   -9.0000 |    9.0000 |   -5.4360 |     3.0000 |   -7.0000 | \n",
      "  229 | 30m00s |    0.70087 |    0.9668 |       9.0000 |   -5.0291 |    6.2086 |   -2.5767 |     1.0000 |   -6.9636 | \n",
      "  230 | 13m36s |    0.70014 |    0.0542 |       7.8253 |   -8.5833 |    8.9661 |   -5.9643 |     1.3687 |   -6.4653 | \n",
      "  231 | 15m18s |    0.69442 |    0.0877 |       8.9138 |   -8.6095 |    5.6238 |   -3.0868 |     1.0331 |   -6.8600 | \n",
      "  232 | 19m41s |    0.68146 |    0.1103 |       8.9600 |   -8.6883 |    8.1089 |   -3.1102 |     1.0347 |   -4.4388 | \n",
      "  233 | 16m32s |    0.65001 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -3.7814 |     1.0000 |   -2.0000 | \n",
      "  234 | 09m28s |    0.64124 |    0.0235 |       7.5707 |   -5.0846 |    7.4359 |   -4.6046 |     2.8688 |   -2.0718 | \n",
      "  235 | 35m31s |    0.70716 |    0.0757 |       8.6918 |   -5.2428 |    5.2777 |   -3.4849 |     1.0234 |   -6.9633 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 45, 'nit': 2, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00036989]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  236 | 11m10s |    0.68997 |    0.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -6.2962 | \n",
      "  237 | 18m32s |    0.70733 |    0.9963 |       9.0000 |   -5.0000 |    6.8404 |   -4.3013 |     1.0000 |   -6.5540 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 51, 'nit': 3, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([3.3684339e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  238 | 20m49s |    0.70358 |    0.0053 |       7.5139 |   -8.8989 |    8.2641 |   -4.4505 |     1.0781 |   -6.3128 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 48, 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-2.29664537e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  239 | 09m35s |    0.69404 |    0.0169 |       9.0000 |   -9.0000 |    6.4374 |   -4.1554 |     1.0465 |   -5.6626 | \n",
      "  240 | 31m25s |    0.72092 |    0.0256 |       8.8903 |   -7.7862 |    8.8627 |   -4.2370 |     2.8784 |   -6.7413 | \n",
      "  241 | 30m21s |    0.71109 |    0.0000 |       8.7999 |   -8.8306 |    8.3088 |   -3.6358 |     2.5510 |   -6.9837 | \n",
      "  242 | 14m11s |    0.70457 |    0.0066 |       8.3418 |   -8.0836 |    8.9023 |   -5.1899 |     2.9534 |   -6.3533 | \n",
      "  243 | 14m05s |    0.67656 |    1.0000 |       7.1799 |   -5.0000 |    8.8911 |   -3.7738 |     1.0000 |   -5.7406 | \n",
      "  244 | 12m16s |    0.67034 |    0.0000 |       5.4960 |   -7.2999 |    6.8918 |   -6.0000 |     2.7191 |   -5.1315 | \n",
      "  245 | 13m09s |    0.68807 |    0.0061 |       8.7325 |   -5.0823 |    5.1791 |   -3.3291 |     2.4448 |   -5.6393 | \n",
      "  246 | 13m55s |    0.68906 |    0.0105 |       8.0545 |   -6.9257 |    8.7350 |   -4.7485 |     1.1742 |   -4.7289 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 46, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([0.00031626]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  247 | 15m33s |    0.71872 |    0.0000 |       8.9993 |   -5.0954 |    8.9081 |   -5.4562 |     2.8641 |   -6.9448 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 49, 'nit': 2, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00023073]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  248 | 19m40s |    0.70348 |    0.8621 |       8.4889 |   -7.2733 |    6.0209 |   -3.5441 |     1.0047 |   -6.9399 | \n",
      "  249 | 23m27s |    0.71049 |    0.0024 |       8.9902 |   -8.3588 |    8.6309 |   -4.3329 |     2.3213 |   -6.8126 | \n",
      "  250 | 12m06s |    0.67477 |    0.0038 |       8.3959 |   -8.6559 |    5.0822 |   -5.5515 |     1.9962 |   -3.1594 | \n",
      "  251 | 27m50s |    0.68328 |    1.0000 |       8.9471 |   -6.4135 |    5.2653 |   -2.3332 |     1.0000 |   -7.0000 | \n",
      "  252 | 15m43s |    0.70792 |    0.0000 |       9.0000 |   -7.6192 |    9.0000 |   -6.0000 |     1.0000 |   -7.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 52, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([5.90625423e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 52, 'nit': 3, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00060243]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  253 | 10m54s |    0.68602 |    1.0000 |       5.0000 |   -9.0000 |    7.3553 |   -6.0000 |     1.0000 |   -5.0402 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 49, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00021296]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  254 | 11m31s |    0.68601 |    0.0172 |       7.5313 |   -5.2191 |    8.8894 |   -5.9573 |     2.8546 |   -5.6873 | \n",
      "  255 | 22m38s |    0.70976 |    0.0002 |       8.8315 |   -7.0184 |    6.9147 |   -4.4529 |     2.1985 |   -5.7915 | \n",
      "  256 | 16m14s |    0.68015 |    0.9025 |       8.8206 |   -6.7162 |    6.5418 |   -4.1950 |     1.0033 |   -3.6151 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 46, 'nit': 3, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([0.00010999]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  257 | 21m18s |    0.70549 |    0.0000 |       8.9222 |   -8.9780 |    9.0000 |   -4.4312 |     3.0000 |   -5.4969 | \n",
      "  258 | 13m17s |    0.71148 |    0.0056 |       8.9477 |   -7.2704 |    8.8443 |   -5.3007 |     2.5603 |   -6.9802 | \n",
      "  259 | 11m35s |    0.69988 |    0.0000 |       9.0000 |   -7.0809 |    6.6577 |   -4.7643 |     2.9964 |   -5.1969 | \n",
      "  260 | 12m52s |    0.69562 |    0.0000 |       8.0202 |   -5.0000 |    5.3597 |   -5.3127 |     2.8661 |   -4.5276 | \n",
      "  261 | 23m30s |    0.71039 |    0.0083 |       8.9427 |   -6.0410 |    7.7315 |   -4.2342 |     2.9323 |   -6.8832 | \n",
      "  262 | 12m29s |    0.68192 |    0.0383 |       9.0000 |   -9.0000 |    7.4756 |   -6.0000 |     1.0481 |   -3.9791 | \n",
      "  263 | 36m21s |    0.65740 |    0.0000 |       5.0000 |   -5.0000 |    9.0000 |   -5.0685 |     3.0000 |   -3.5840 | \n",
      "  264 | 19m58s |    0.66744 |    0.1535 |       6.6704 |   -8.9895 |    6.7044 |   -4.3979 |     1.0313 |   -5.7500 | \n",
      "  265 | 20m04s |    0.71400 |    0.0084 |       8.9286 |   -5.9744 |    8.9850 |   -4.3299 |     1.4342 |   -6.9606 | \n",
      "  266 | 16m48s |    0.69822 |    0.0000 |       8.3321 |   -9.0000 |    8.8133 |   -3.6623 |     1.0000 |   -5.3743 | \n",
      "  267 | 19m04s |    0.62851 |    0.9750 |       5.3749 |   -7.8730 |    7.7693 |   -5.9703 |     1.0366 |   -2.7889 | \n",
      "  268 | 26m45s |    0.68378 |    0.0000 |       6.5863 |   -9.0000 |    9.0000 |   -6.0000 |     1.0000 |   -4.9372 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 52, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00016248]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  269 | 17m28s |    0.70789 |    0.0000 |       9.0000 |   -8.5868 |    5.0000 |   -4.1334 |     1.0000 |   -5.0999 | \n",
      "  270 | 18m44s |    0.71346 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -3.8339 |     1.0000 |   -7.0000 | \n",
      "  271 | 09m38s |    0.65432 |    0.0000 |       7.6240 |   -7.2237 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  272 | 14m15s |    0.66785 |    0.0241 |       8.0906 |   -6.8114 |    6.0104 |   -5.7197 |     2.9366 |   -3.6154 | \n",
      "  273 | 17m02s |    0.68674 |    0.0000 |       7.2964 |   -5.0000 |    5.0000 |   -4.3448 |     2.9985 |   -3.3045 | \n",
      "  274 | 16m47s |    0.69421 |    0.0000 |       6.8631 |   -6.9836 |    8.9967 |   -5.6447 |     2.6994 |   -5.0971 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 47, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00049825]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  275 | 20m57s |    0.70810 |    0.0000 |       9.0000 |   -5.0000 |    7.9623 |   -4.4911 |     3.0000 |   -6.8655 | \n",
      "  276 | 16m43s |    0.70801 |    0.0000 |       9.0000 |   -6.8407 |    9.0000 |   -4.5540 |     3.0000 |   -6.3089 | \n",
      "  277 | 16m33s |    0.70391 |    0.0000 |       8.1880 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -4.2084 | \n",
      "  278 | 43m58s |    0.69229 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "  279 | 19m35s |    0.65391 |    0.0000 |       5.0000 |   -5.0000 |    5.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  280 | 22m19s |    0.71713 |    0.9932 |       9.0000 |   -6.4341 |    6.5974 |   -3.9520 |     1.0000 |   -6.4406 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 47, 'nit': 2, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00056121]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 47, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-1.46792954e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  281 | 11m31s |    0.70410 |    0.0000 |       9.0000 |   -7.4152 |    9.0000 |   -6.0000 |     3.0000 |   -7.0000 | \n",
      "  282 | 10m33s |    0.66363 |    0.0000 |       8.0856 |   -9.0000 |    7.8405 |   -4.5382 |     2.0369 |   -2.0980 | \n",
      "  283 | 19m47s |    0.64168 |    0.0000 |       5.0000 |   -9.0000 |    9.0000 |   -6.0000 |     3.0000 |   -2.0000 | \n",
      "  284 | 17m38s |    0.70446 |    0.0287 |       8.9561 |   -7.4083 |    7.6465 |   -5.1436 |     1.0269 |   -6.4048 | \n",
      "  285 | 19m09s |    0.70113 |    0.0034 |       8.6852 |   -7.8578 |    7.9303 |   -4.1396 |     2.0033 |   -6.2574 | \n",
      "  286 | 19m54s |    0.70752 |    0.0145 |       8.9929 |   -5.2287 |    5.7881 |   -4.0461 |     2.0425 |   -6.9040 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 45, 'nit': 2, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00010488]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  287 | 09m40s |    0.67937 |    0.0023 |       8.8170 |   -6.4274 |    6.1206 |   -4.7279 |     1.0000 |   -4.4028 | \n",
      "  288 | 13m59s |    0.70443 |    0.0000 |       9.0000 |   -5.0000 |    5.0000 |   -4.5203 |     3.0000 |   -5.4422 | \n",
      "  289 | 12m35s |    0.64473 |    0.0000 |       7.0049 |   -7.1217 |    5.0001 |   -4.6247 |     1.0000 |   -2.0000 | \n",
      "  290 | 42m15s |    0.69589 |    0.0010 |       7.6534 |   -8.9043 |    9.0000 |   -4.3178 |     3.0000 |   -7.0000 | \n",
      "  291 | 24m09s |    0.69187 |    0.0000 |       7.0485 |   -5.0487 |    5.0000 |   -3.7092 |     1.0000 |   -7.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 52, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00012374]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 51, 'nit': 3, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-8.47628907e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  292 | 15m50s |    0.71132 |    0.9842 |       8.8892 |   -6.1505 |    7.4759 |   -4.4260 |     1.0401 |   -6.9814 | \n",
      "  293 | 35m21s |    0.71314 |    0.0087 |       8.8562 |   -5.0977 |    7.1188 |   -3.9991 |     1.7295 |   -6.9483 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 52, 'nit': 4, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-9.2092056e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  294 | 15m09s |    0.66466 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -6.0000 |     1.0000 |   -2.0000 | \n",
      "  295 | 11m33s |    0.69333 |    0.0000 |       9.0000 |   -7.2633 |    9.0000 |   -6.0000 |     1.9968 |   -5.4874 | \n",
      "  296 | 17m25s |    0.70056 |    0.9582 |       7.0725 |   -7.0179 |    7.5335 |   -5.8976 |     1.0000 |   -6.2928 | \n",
      "  297 | 21m18s |    0.69526 |    0.1120 |       8.9989 |   -5.1183 |    7.5400 |   -3.4219 |     1.0064 |   -6.9847 | \n",
      "  298 | 21m24s |    0.71019 |    0.8268 |       8.8904 |   -5.3967 |    8.5838 |   -4.0255 |     1.0000 |   -5.5484 | \n",
      "  299 | 14m30s |    0.69953 |    0.9506 |       7.9186 |   -6.9406 |    7.5323 |   -4.6780 |     1.0000 |   -5.4461 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 51, 'nit': 3, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([1.40503425e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  300 | 25m41s |    0.70398 |    0.0000 |       9.0000 |   -8.0320 |    9.0000 |   -3.8510 |     1.0000 |   -6.2625 | \n",
      "  301 | 43m53s |    0.69904 |    0.5600 |       8.2432 |   -5.0000 |    6.9343 |   -3.9727 |     1.0000 |   -7.0000 | \n",
      "  302 | 28m59s |    0.68139 |    0.0000 |       9.0000 |   -9.0000 |    5.0000 |   -6.0000 |     1.0000 |   -3.5051 | \n",
      "  303 | 29m43s |    0.72027 |    0.0000 |       9.0000 |   -9.0000 |    9.0000 |   -3.7377 |     2.9646 |   -7.0000 | \n",
      "  304 | 13m55s |    0.69028 |    0.0000 |       8.8041 |   -9.0000 |    6.5266 |   -5.4608 |     2.4941 |   -4.5788 | \n",
      "  305 | 14m22s |    0.69573 |    1.0000 |       9.0000 |   -5.0000 |    9.0000 |   -5.2063 |     1.0000 |   -5.5004 | \n",
      "  306 | 18m02s |    0.69963 |    0.0000 |       7.1030 |   -6.6500 |    7.2623 |   -6.0000 |     1.0000 |   -4.6531 | \n",
      "  307 | 16m17s |    0.67360 |    1.0000 |       9.0000 |   -5.0000 |    8.7148 |   -3.3439 |     1.0000 |   -4.4013 | \n",
      "Error in iteration: 101, ignore result\n",
      "Error in iteration: 102, ignore result\n",
      "Error in iteration: 103, ignore result\n",
      "Error in iteration: 104, ignore result\n",
      "Error in iteration: 105, ignore result\n",
      "Error in iteration: 106, ignore result\n",
      "Error in iteration: 107, ignore result\n",
      "Error in iteration: 108, ignore result\n",
      "Error in iteration: 109, ignore result\n",
      "Error in iteration: 110, ignore result\n",
      "Error in iteration: 111, ignore result\n",
      "Error in iteration: 112, ignore result\n",
      "Error in iteration: 113, ignore result\n",
      "Error in iteration: 114, ignore result\n",
      "Error in iteration: 115, ignore result\n",
      "Error in iteration: 116, ignore result\n",
      "Error in iteration: 117, ignore result\n",
      "Error in iteration: 118, ignore result\n",
      "Error in iteration: 119, ignore result\n",
      "Error in iteration: 120, ignore result\n",
      "Error in iteration: 121, ignore result\n",
      "Error in iteration: 122, ignore result\n",
      "Error in iteration: 123, ignore result\n",
      "Error in iteration: 124, ignore result\n",
      "Error in iteration: 125, ignore result\n",
      "Error in iteration: 126, ignore result\n",
      "Error in iteration: 127, ignore result\n",
      "Error in iteration: 128, ignore result\n",
      "Error in iteration: 129, ignore result\n",
      "Error in iteration: 130, ignore result\n",
      "Error in iteration: 131, ignore result\n",
      "Error in iteration: 132, ignore result\n",
      "Error in iteration: 133, ignore result\n",
      "Error in iteration: 134, ignore result\n",
      "Error in iteration: 135, ignore result\n",
      "  308 | 666m12s |    0.70809 |    0.0014 |       8.7741 |   -8.9855 |    8.1532 |   -4.4133 |     2.8165 |   -6.1750 | \n",
      "  309 | 57m23s |    0.67158 |    0.0000 |       8.1901 |   -8.1031 |    8.8428 |   -4.0400 |     1.0000 |   -3.4591 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 44, 'nit': 1, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([7.78166567e-05]), 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  310 | 43m48s |    0.68553 |    0.0169 |       8.9506 |   -6.9853 |    5.1288 |   -3.2344 |     1.0923 |   -5.3690 | \n"
     ]
    }
   ],
   "source": [
    "# I might need to get rid of the loop now, if I want to put initialized point into them, let't just test plain RNN with Adamax\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-4}\n",
    "\n",
    "#Here we loop through different models, change the model tune \n",
    "#for cti in range(1,4): \n",
    "    #for dlmi in range(1,2): #just the RNN, no DRNN\n",
    "        #for opti in range(1,8):\n",
    "            #print('\\n Now Tuning model with Bayesian Optimization: ','cell code', str(cti),'model code', str(dlmi),'optimizer code',str(opti))\n",
    "NNBO = BayesianOptimization(model_tune,\n",
    "                            {#'dlm_code':(dlmi,dlmi), 'ct_code': (cti, cti), 'opt_code':(opti, opti),\n",
    "                             'embdim_exp': (5, 9),'hid_exp': (5, 9),'layers_n': (1, 3),'dropout': (0, 1),\n",
    "                             'l2_exp': (-6, -1), 'lr_exp': (-7, -2), 'eps_exp': (-9, -5)})\n",
    "\n",
    "#add previously explored points to initialized points \n",
    "NNBO.initialize_df(init_df)\n",
    "'''\n",
    " {\n",
    "    'target': [-1166.19102, -1142.71370, -1138.68293],\n",
    "    'alpha': [7.0034, 6.6186, 6.0798],\n",
    "    'colsample_bytree': [0.6849, 0.7314, 0.9540],\n",
    "    'gamma': [8.3673, 3.5455, 2.3281],\n",
    "}\n",
    "\n",
    "param points_df:\n",
    "pandas dataframe with columns (target, {list of columns matching\n",
    "self.keys})\n",
    "\n",
    "ex:\n",
    "      target        alpha      colsample_bytree        gamma\n",
    "-1166.19102       7.0034                0.6849       8.3673\n",
    "-1142.71370       6.6186                0.7314       3.5455\n",
    "-1138.68293       6.0798                0.9540       2.3281\n",
    "-1146.65974       2.4566                0.9290       0.3456\n",
    "-1160.32854       1.9821                0.5298       8.7863\n",
    "\n",
    "'''   \n",
    "\n",
    "\n",
    "NNBO.explore({#'dlm_code':[dlmi], 'ct_code': [cti], 'opt_code':[opti],\n",
    "             'embdim_exp': [8],'hid_exp': [8],'layers_n': [1],'dropout': [0.1],\n",
    "              'l2_exp': [-3], 'lr_exp': [-3], 'eps_exp':[-6]}, eager = True)\n",
    "\n",
    "\n",
    "NNBO.maximize(n_iter= 10000, **gp_params)\n",
    "\n",
    "print('-' * 53)\n",
    "print('Final Results')\n",
    "print('RNN / DRNN: %f' % NNBO.res['max']['max_val'])\n",
    "\n",
    "print2file(str(NNBO.res['max']), logFile)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-4}\n",
    "\n",
    "#Here we loop through different models, change the model tune \n",
    "for cti in range(1,4): \n",
    "    for dlmi in range(1,2): #just the RNN, no DRNN\n",
    "        for opti in range(1,8):\n",
    "            print('\\n Now Tuning model with Bayesian Optimization: ','cell code', str(cti),'model code', str(dlmi),'optimizer code',str(opti))\n",
    "            NNBO = BayesianOptimization(model_tune,\n",
    "                                        {'dlm_code':(dlmi,dlmi), 'ct_code': (cti, cti), 'opt_code':(opti, opti),\n",
    "                                         'embdim_exp': (5, 9),'hid_exp': (5, 9),'layers_n': (1, 3),'dropout': (0, 1),\n",
    "                                         'l2_exp': (-6, -1), 'lr_exp': (-7, -2), 'eps_exp': (-9, -5)})\n",
    "            \n",
    "            #add previously explored points to initialized points \n",
    "            NNBO.initialize_df(  {\n",
    "                'target': [-1166.19102, -1142.71370, -1138.68293],\n",
    "                'alpha': [7.0034, 6.6186, 6.0798],\n",
    "                'colsample_bytree': [0.6849, 0.7314, 0.9540],\n",
    "                'gamma': [8.3673, 3.5455, 2.3281],\n",
    "            })\n",
    "         '''\n",
    "            param points_df:\n",
    "            pandas dataframe with columns (target, {list of columns matching\n",
    "            self.keys})\n",
    "\n",
    "            ex:\n",
    "                  target        alpha      colsample_bytree        gamma\n",
    "            -1166.19102       7.0034                0.6849       8.3673\n",
    "            -1142.71370       6.6186                0.7314       3.5455\n",
    "            -1138.68293       6.0798                0.9540       2.3281\n",
    "            -1146.65974       2.4566                0.9290       0.3456\n",
    "            -1160.32854       1.9821                0.5298       8.7863\n",
    "\n",
    "         '''   \n",
    "        \n",
    "            \n",
    "            NNBO.explore({'dlm_code':[dlmi], 'ct_code': [cti], 'opt_code':[opti],'embdim_exp': [8],\n",
    "                          'hid_exp': [8],'layers_n': [1],'dropout': [0.1],'l2_exp': [-3], 'lr_exp': [-3], 'eps_exp':[-6]}, eager = True)\n",
    "\n",
    "            #NNBO.maximize(n_iter=10000, **gp_params)\n",
    "            #try different kappas\n",
    "            for kappa in [10, 5, 1]:\n",
    "                NNBO.maximize(acq='ucb', kappa=kappa, **gp_params)\n",
    "\n",
    "            print('-' * 53)\n",
    "            print('Final Results')\n",
    "            print('RNN / DRNN: %f' % NNBO.res['max']['max_val'])\n",
    "\n",
    "            print2file(str(NNBO.res['max']), logFile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for kappa in [10, 5, 1]:\n",
    "    NNBO.maximize(acq='ucb', kappa=kappa, **gp_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
