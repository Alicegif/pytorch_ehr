{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_gp as model # need to check and modify\n",
    "import Loaddata as Loaddata\n",
    "import TrainVaTe as TVT\n",
    "\n",
    "# check GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing data...\n",
      "\n",
      "Sample data after split:\n",
      "[0, [1667, 144, 62, 85, 1667, 144, 62, 85]]\n",
      "model is LR\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "set_x = pickle.load(open('Data/h143.visits', 'rb'), encoding='bytes')\n",
    "set_y = pickle.load(open('Data/h143.labels', 'rb'),encoding='bytes')\n",
    "\n",
    "model_x = []\n",
    "for patient in set_x:\n",
    "    model_x.append([each for visit in patient for each in visit])  \n",
    "    \n",
    "merged_set= [[set_y[i],model_x[i]] for i in range(len(set_y))]\n",
    "print(\"\\nLoading and preparing data...\")    \n",
    "train1, valid1, test1 = Loaddata.load_data(merged_set)\n",
    "print(\"\\nSample data after split:\")  \n",
    "print(train1[0])\n",
    "print(\"model is\", 'LR') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to record comprehensive searching results \n",
    "def print2file(buf, outFile):\n",
    "    outfd = open(outFile, 'a')\n",
    "    outfd.write(buf + '\\n')\n",
    "    outfd.close()\n",
    "\n",
    "logFile='testLR.log'\n",
    "header = 'model|emb_dim|l2|lr|BestValidAUC|TestAUC|atEpoch'\n",
    "print2file(header, logFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamters to tune for LR: embed_dim, l2, lr. Define a function to return the validation AUC of the model \n",
    "def LR_tune(embed_dim, l2, lr):\n",
    "    #little transformations to use the searched values\n",
    "    embed_dim = 2 ** int(embed_dim) #base 2 \n",
    "    l2 = np.exp(l2) #base e\n",
    "    lr = np.exp(lr) #base e\n",
    "    ehr_model = model.EHR_LR(embed_dim = embed_dim)  \n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda()\n",
    "    optimizer = optim.Adam(ehr_model.parameters(), lr=lr, weight_decay=l2)\n",
    "    #current_loss_allep=[]\n",
    "    #all_losses_allep=[]\n",
    "    #avg_losses_allep=[]\n",
    "    #train_auc_allep =[]\n",
    "    #valid_auc_allep =[]\n",
    "    #test_auc_allep=[]\n",
    "    \n",
    "    bestValidAuc = 0.0\n",
    "    bestTestAuc = 0.0\n",
    "    bestValidEpoch = 0\n",
    "    \n",
    "    for ep in range(25):\n",
    "        #start = time.time()\n",
    "        current_loss, train_loss = TVT.train(train1, model= ehr_model, optimizer = optimizer, batch_size = 1) #mb=args.mb\n",
    "        avg_loss = np.mean(train_loss)\n",
    "        #train_time = timeSince(start)\n",
    "        #print ('\\n Current running on: Epoch ', ep,'Training loss:',' Average loss', avg_loss)\n",
    "        #print(train_loss, '\\n train loss plot')\n",
    "        #TVT.showPlot(train_loss)\n",
    "        #eval_start = time.time()\n",
    "        #train_auc, y_real, y_hat = TVT.calculate_auc(model= ehr_model, data = train1, which_model ='LR', batch_size = 1)\n",
    "        #print ('\\n Current running on: Epoch ', ep,' Training auc:', train_auc)\n",
    "        #TVT.auc_plot(y_real, y_hat)\n",
    "        valid_auc, y_real, y_hat  = TVT.calculate_auc(model = ehr_model, data = valid1, which_model = 'LR', batch_size = 1)\n",
    "        #print ('\\n Current running on: Epoch ', ep,' validation auc:', valid_auc)\n",
    "        #TVT.auc_plot(y_real, y_hat)\n",
    "        if valid_auc > bestValidAuc: \n",
    "            bestValidAuc = valid_auc\n",
    "            bestValidEpoch = ep\n",
    "            bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = ehr_model, data = test1, which_model = 'LR', batch_size = 1)\n",
    "\n",
    "        if ep - bestValidEpoch >5:\n",
    "            break\n",
    "        \n",
    "      \n",
    "        buf = '|%f |%f |%d ' % (bestValidAuc, bestTestAuc, bestValidEpoch)\n",
    "        pFile= 'LR'+'|'+str(embed_dim)+'|'+str(l2)+'|'+str(lr)+'|'+buf    \n",
    "        print2file(pFile, logFile)      \n",
    "        \n",
    "        #test_auc, y_real, y_hat = TVT.calculate_auc(model = ehr_model, data = test1, which_model = 'LR', batch_size = 1)\n",
    "        #print ('\\n Current running on: Epoch ', ep,' test auc:', test_auc)\n",
    "        #TVT.auc_plot(y_real, y_hat)\n",
    "        #eval_time = timeSince(eval_start)\n",
    "        #print (\"Epoch \", ep, \"Summary:  Training_auc :\", train_auc, \" , Validation_auc : \", valid_auc, \" ,& Test_auc : \" , test_auc, \" Avg Loss: \", avg_loss )\n",
    "        #current_loss_allep.append(current_loss)\n",
    "        #all_losses_allep.append(train_loss)\n",
    "        #avg_losses_allep.append(avg_loss)\n",
    "        #train_auc_allep.append(train_auc)\n",
    "        #valid_auc_allep.append(valid_auc)\n",
    "        #test_auc_allep.append(test_auc)\n",
    "        #final_max_valid = max(valid_auc_allep)\n",
    "    return bestValidAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   embed_dim |        l2 |        lr | \n",
      "    1 | 15m31s | \u001b[35m   0.77016\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m -11.0000\u001b[0m | \u001b[32m  -9.0000\u001b[0m | \n",
      "    2 | 09m56s |    0.65682 |      7.0153 |   -4.0200 |   -5.4448 | \n",
      "    3 | 11m11s | \u001b[35m   0.77134\u001b[0m | \u001b[32m     7.4061\u001b[0m | \u001b[32m  -5.6801\u001b[0m | \u001b[32m  -8.3787\u001b[0m | \n",
      "    4 | 08m44s |    0.74046 |      1.9991 |  -14.9532 |   -4.9908 | \n",
      "    5 | 04m18s |    0.59687 |      2.4018 |   -2.3075 |   -4.9971 | \n",
      "    6 | 06m59s |    0.54415 |      1.5349 |   -3.3380 |   -2.8736 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   embed_dim |        l2 |        lr | \n",
      "    7 | 20m33s |    0.71027 |      8.0000 |  -16.0000 |  -11.0000 | \n",
      "    8 | 10m32s |    0.58465 |      8.0000 |    1.0000 |  -11.0000 | \n",
      "    9 | 21m49s |    0.53766 |      8.0000 |  -16.0000 |   -2.0000 | \n",
      "   10 | 16m27s |    0.63535 |      0.0000 |  -16.0000 |  -11.0000 | \n",
      "   11 | 16m22s |    0.73416 |      5.9025 |   -9.3511 |  -11.0000 | \n",
      "   12 | 16m29s |    0.65338 |      0.0000 |   -4.0650 |  -11.0000 | \n",
      "   13 | 28m27s |    0.75897 |      8.0000 |  -11.0370 |   -7.5004 | \n",
      "   14 | 11m38s | \u001b[35m   0.77410\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m -10.5920\u001b[0m | \u001b[32m  -5.2683\u001b[0m | \n",
      "   15 | 09m04s | \u001b[35m   0.77418\u001b[0m | \u001b[32m     3.5652\u001b[0m | \u001b[32m  -9.2751\u001b[0m | \u001b[32m  -7.0005\u001b[0m | \n",
      "   16 | 11m57s |    0.76914 |      0.0000 |  -12.0243 |   -6.8047 | \n",
      "   17 | 22m40s |    0.76888 |      8.0000 |   -7.3694 |   -9.7832 | \n",
      "   18 | 14m17s | \u001b[35m   0.77982\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m  -8.8122\u001b[0m | \u001b[32m  -7.0593\u001b[0m | \n",
      "   19 | 06m30s |    0.75864 |      3.0146 |  -11.5299 |   -7.2485 | \n",
      "   20 | 04m53s |    0.59581 |      0.0000 |  -16.0000 |   -2.0000 | \n",
      "   21 | 12m03s |    0.77705 |      0.0007 |   -8.9440 |   -7.4484 | \n",
      "   22 | 07m19s |    0.77226 |      3.5753 |   -7.6962 |   -8.0666 | \n",
      "   23 | 08m15s |    0.77557 |      0.0015 |  -10.2799 |   -6.9083 | \n",
      "   24 | 18m10s |    0.77588 |      8.0000 |   -8.5190 |   -8.5442 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 49, 'warnflag': 2, 'grad': array([-3.22080159e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'nit': 3}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 10m15s |    0.77166 |      1.4851 |   -9.8711 |   -6.9459 | \n",
      "   26 | 08m53s |    0.76915 |      5.9699 |   -8.1378 |   -8.2801 | \n",
      "   27 | 06m05s |    0.77147 |      0.0095 |  -10.8550 |   -6.9711 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 56, 'warnflag': 2, 'grad': array([-1.55050987e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'nit': 6}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 14m15s |    0.77765 |      8.0000 |   -6.3627 |  -10.1488 | \n",
      "   29 | 12m37s |    0.76204 |      7.9997 |   -7.7332 |   -8.6366 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jzhu8/.local/lib/python3.5/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'funcalls': 53, 'warnflag': 2, 'grad': array([-1.41626623e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'nit': 4}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 | 09m57s |    0.77800 |      1.5723 |   -9.0584 |   -7.4388 | \n",
      "   31 | 09m29s |    0.77830 |      0.0000 |   -9.3183 |   -7.0891 | \n",
      "   32 | 19m28s |    0.76878 |      7.9978 |   -5.7608 |  -11.0000 | \n",
      "   33 | 04m58s |    0.77346 |      1.5647 |  -10.2258 |   -6.7250 | \n",
      "   34 | 07m05s |    0.77447 |      0.0064 |   -8.9613 |   -7.1064 | \n",
      "   35 | 09m47s |    0.77240 |      0.0255 |  -10.8283 |   -7.1434 | \n",
      "   36 | 07m00s |    0.77170 |      5.4919 |   -6.4287 |   -9.1667 | \n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "LR: 0.779816\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-4}\n",
    "\n",
    "    LRBO = BayesianOptimization(LR_tune,\n",
    "        {'embed_dim':(0, 8),'l2': (-16, 1), 'lr': (-11, -2) })\n",
    "    LRBO.explore({'embed_dim':[1],'l2': [-11], 'lr': [-9]})\n",
    "\n",
    "    LRBO.maximize(n_iter=30, **gp_params)\n",
    "\n",
    "    print('-' * 53)\n",
    "    print('Final Results')\n",
    "    print('LR: %f' % LRBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014890530365549773"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l2\n",
    "np.exp(-8.8122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008593794490898537"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr \n",
    "np.exp(-7.0593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
