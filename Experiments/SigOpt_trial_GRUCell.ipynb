{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to demonstrate how to use SigOpt software for hyperparameter tuning:\n",
    "\n",
    "* After importing necessary modules, first create a connection to SigOpt API, you will need an account that you can sign up here: <https://sigopt.com/edu> and get the client token under the tab **API Tokens**\n",
    "* Do the normal steps of Bayesian Optimization up till the creation of the function model_tune() which takes in the hyperparameters and return the best validation AUC (sidenote: since everything will be recorded at SigOpt API and you can download it as csv file later, you can get rid of recording searched parameters on your own)\n",
    "* Then **important**: create an experiment with the connection to SigOpt API specifying the experiment name, the hypreparameters searching space, the type of hyperparameters (int, float, categorical), and finally observation budget (which is the number of iterations). I have all types in here already, so you can just copy as needed\n",
    "* You can print out the experiment id link so you can easily check out experiment results\n",
    "* Then **important**: you will need an function to pass the parameters you created in the experiments to model_tune(). Assignments are the default results from experiments, so you need to call 'assignments' dictionary for different hyperparameters\n",
    "* Then **important**: create iterations(observations), the API will automatically update suggestions based on best result\n",
    "* Then fetch the best experiment results after all iterations are done, but you can also manually retrieve the result at the experiment id link above\n",
    "* Additional infor that might be need: delete an experiment (free trial account has 10 experiments limit, so be sure to manage your unwanted ones\n",
    "* Model parameter by SigOpt: RNN with GRU cell, SigOpt gives the best validation AUC of 0.807\n",
    "* Hyperparameters tested: dropout: **0.5519603420905197**; embdim_exp: **9**; eps_exp: **-5**; hid_exp: **9**; l2_exp: **-5**; layers_n: **1**; lr_exp: **-2**; opt_code: **Adam**  [click here](https://sigopt.com/guest?guest_token=FQAAQHWMAMOEWSVMBOTLESAPXZOGXZQSJNOUQCSPZQNSXFCZ)\n",
    "* Local result: using the same set of parameters, run the RNN model locally on server, it gives us a result of **0.794 best validation auc**, with corresponding **0.796 test auc**. Difference exists but minor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "#from bayes_opt import BayesianOptimization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigopt import Connection\n",
    "conn = Connection(client_token='QULCGRMSXQAMRSTUPJPLAHDCHJMEMLXPSPZSQMWNEYKHLYJF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_HPS_V2 as model #this changed\n",
    "import Loaddata_final as Loaddata\n",
    "import TrVaTe_V2 as TVT #This changed \n",
    "\n",
    "# check GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing data...\n",
      "\n",
      "Sample data after split:\n",
      "[0, [[491, 129, 813, 149, 84, 85], [491, 129, 813, 61, 84, 85], [358, 61, 84, 85], [491, 1250, 813, 61, 84, 85], [499, 61, 84, 85], [499, 61, 84, 85], [8004, 61, 84, 85], [2914, 61, 84, 85], [2914, 61, 84, 85], [2499, 499, 61, 84, 85], [499, 61, 84, 85], [1250, 129, 813, 61, 84, 85], [1250, 61, 84, 85]]]\n",
      "model is RNN_GRU\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "set_x = pickle.load(open('Data/h143.visits', 'rb'), encoding='bytes')\n",
    "set_y = pickle.load(open('Data/h143.labels', 'rb'),encoding='bytes')\n",
    "\n",
    "\"\"\"\n",
    "model_x = []\n",
    "for patient in set_x:\n",
    "    model_x.append([each for visit in patient for each in visit])  \n",
    "    \n",
    "\"\"\"\n",
    "model_x = set_x  #this is for the rest of the models\n",
    "    \n",
    "merged_set= [[set_y[i],model_x[i]] for i in range(len(set_y))] #list of list or list of lists of lists\n",
    "print(\"\\nLoading and preparing data...\")    \n",
    "train1, valid1, test1 = Loaddata.load_data(merged_set)\n",
    "print(\"\\nSample data after split:\")  \n",
    "print(train1[1])\n",
    "print(\"model is\", 'RNN_GRU') #can change afterwards, currently on most basic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on RNN with celltype plain RNN, with differnent optimizers also as an option \n",
    "def model_tune(embdim_exp, hid_exp, layers_n, dropout, l2_exp , lr_exp, eps_exp, opt_code):\n",
    "    #little transformations to use the searched values\n",
    "    embed_dim = 2** int(embdim_exp)\n",
    "    hidden_size = 2** int(hid_exp)\n",
    "    n_layers = int(layers_n)\n",
    "    dropout = round(dropout, 4)\n",
    "    l2 = 10** int(l2_exp)\n",
    "    lr = 10** int(lr_exp)\n",
    "    eps = 10** (eps_exp)\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "   #dealing with categorical data\n",
    "    if int(dlm_code)<3:\n",
    "      if int(ct_code) ==1:\n",
    "          cell_type='RNN'   \n",
    "      elif int(ct_code) ==2:\n",
    "          cell_type='LSTM'\n",
    "      elif int(ct_code) ==3:\n",
    "          cell_type='GRU'\n",
    "      \n",
    "    if int(dlm_code)==1:\n",
    "        w_model='RNN'\n",
    "        ehr_model = model.EHR_RNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type)\n",
    "    elif int(dlm_code)==2:\n",
    "        w_model='DRNN'\n",
    "        ehr_model = model.DRNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type)\n",
    "\n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda(0)    \n",
    "        \n",
    "    \"\"\"    \n",
    "       \n",
    "    ehr_model = model.EHR_RNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type = 'RNN')\n",
    "\n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda(0)   \n",
    "    \n",
    "    if opt_code == 'Adadelta':\n",
    "        opt= 'Adadelta'\n",
    "        optimizer = optim.Adadelta(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps) ## rho=0.9\n",
    "    elif opt_code == 'Adagrad':\n",
    "        opt= 'Adagrad'\n",
    "        optimizer = optim.Adagrad(ehr_model.parameters(), lr=lr, weight_decay=l2) ##lr_decay no eps\n",
    "    elif opt_code =='Adam':\n",
    "        opt= 'Adam'\n",
    "        optimizer = optim.Adam(ehr_model.parameters(), lr=lr, weight_decay=l2,eps=eps ) ## Beta defaults (0.9, 0.999), amsgrad (false)\n",
    "    elif opt_code =='Adamax':\n",
    "        opt= 'Adamax'\n",
    "        optimizer = optim.Adamax(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps) ### Beta defaults (0.9, 0.999)\n",
    "    elif opt_code =='RMSprop':\n",
    "        opt= 'RMSprop'\n",
    "        optimizer = optim.RMSprop(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps)                \n",
    "    elif opt_code =='ASGD':\n",
    "        opt= 'ASGD'\n",
    "        optimizer = optim.ASGD(ehr_model.parameters(), lr=lr, weight_decay=l2 ) ### other parameters\n",
    "    elif opt_code =='SGD':\n",
    "        opt= 'SGD'\n",
    "        optimizer = optim.SGD(ehr_model.parameters(), lr=lr, weight_decay=l2 ) ### other parameters\n",
    "  \n",
    "    \"\"\"\n",
    "    ehr_model = model.EHR_RNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type = 'RNN')\n",
    "\n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda(0)    \n",
    "        \n",
    "    optimizer = optim.Adamax(ehr_model.parameters(), lr=lr, weight_decay=l2,eps=eps)    \n",
    "   \n",
    "    \"\"\"\n",
    "     \n",
    "    bestValidAuc = 0.0\n",
    "    bestTestAuc = 0.0\n",
    "    bestValidEpoch = 0\n",
    "  \n",
    "    for ep in range(epochs):\n",
    "        current_loss, train_loss = TVT.train(train1, model= ehr_model, optimizer = optimizer, batch_size = 200)\n",
    "        avg_loss = np.mean(train_loss)\n",
    "        valid_auc, y_real, y_hat  = TVT.calculate_auc(model = ehr_model, data = valid1, which_model = 'RNN', batch_size = 200)\n",
    "        if valid_auc > bestValidAuc: \n",
    "            bestValidAuc = valid_auc\n",
    "            bestValidEpoch = ep\n",
    "            best_model= ehr_model\n",
    "            #bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = ehr_model, data = test1, which_model = w_model, batch_size = 200)\n",
    "\n",
    "        if ep - bestValidEpoch > 12:\n",
    "            break\n",
    "      \n",
    "  \n",
    "     \n",
    "    #fname= 'RNN'+'E'+str(embed_dim)+'RNN'+'L'+str(n_layers)+'H'+str(hidden_size)+'D'+str(dropout)+'Adamax'+'L'+str(lr)+'P'+str(l2)  \n",
    "    #bmodel_pth='models/'#+fname\n",
    "    bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = best_model, data = test1, which_model = 'RNN', batch_size = 200)\n",
    "    #torch.save(best_model, bmodel_pth)\n",
    "    #buf = '|%f |%f |%d ' % (bestValidAuc, bestTestAuc, bestValidEpoch )\n",
    "    \n",
    "    #pFile= 'RNN'+'|'+str(embdim_exp)+'|'+'RNN'+'|'+str(layers_n)+'|'+str(hid_exp)+'|'+str(dropout)+'|'+'Adamax'+'|'+str(lr_exp)+'|'+str(l2_exp)+'|'+str(eps_exp)+ buf  \n",
    "    #print2file(pFile, logFile)\n",
    "    print('n/best validation auc: ' + str(bestValidAuc))\n",
    "    print('n/best test auc: ' + str(bestTestAuc))\n",
    "    return bestValidAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 different experiments for 3 different cells, keep the optimizer categorical \n",
    "experiment = conn.experiments().create(\n",
    "  name='RNNGRU_AUC_Optimization',\n",
    "  parameters=[\n",
    "    dict(name='embdim_exp', type='int', bounds=dict(min=5, max=9)),\n",
    "    dict(name='hid_exp', type='int', bounds=dict(min=5, max=9)),\n",
    "    dict(name='layers_n', type='int', bounds=dict(min=1, max=3)),\n",
    "    dict(name='dropout', type='double', bounds=dict(min=0.1000, max= 0.9000)),\n",
    "    dict(name='lr_exp', type='int', bounds=dict(min=-7, max=-2)), \n",
    "    dict(name='l2_exp', type='int', bounds=dict(min=-7, max=-1)),\n",
    "    dict(name='eps_exp', type='int', bounds=dict(min=-9, max=-4)),  \n",
    "    dict(name='opt_code', type='categorical', categorical_values=[dict(name='Adadelta'), dict(name='Adagrad'),\n",
    "                                                                  dict(name='Adam'), dict(name='Adamax'),dict(name='RMSprop'),\n",
    "                                                                  dict(name='ASGD'), dict(name='SGD')]),\n",
    "  ],\n",
    "  observation_budget=300 #10~20 times number of parameters \n",
    "  )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " metadata=dict(\n",
    "    template=\"pytorch_mlp\"\n",
    "    ),\n",
    "  observation_budget=70\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: https://sigopt.com/experiment/44631\n"
     ]
    }
   ],
   "source": [
    "print(\"Created experiment: https://sigopt.com/experiment/\" + experiment.id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model with the suggested parameter assignments\n",
    "def evaluate_model(assignments):\n",
    "  return model_tune(assignments['embdim_exp'], assignments['hid_exp'],assignments['layers_n'],assignments['dropout'],\n",
    "                    assignments['lr_exp'],assignments['l2_exp'],assignments['eps_exp'],assignments['opt_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the experiments, no need to modify\n",
    "for i in range(300):\n",
    "  suggestion = conn.experiments(experiment.id).suggestions().create()\n",
    "  value = evaluate_model(suggestion.assignments)\n",
    "  conn.experiments(experiment.id).observations().create(\n",
    "    suggestion=suggestion.id,\n",
    "    value=value,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapping up the experiments and get the results\n",
    "best_assignments_list = (\n",
    "    conn.experiments('44631')\n",
    "        .best_assignments()\n",
    "        .fetch()\n",
    ")\n",
    "if best_assignments_list.data:\n",
    "    best_assignments = best_assignments_list.data[0].assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assignments({\n",
       "  \"dropout\": 0.5519603420905197,\n",
       "  \"embdim_exp\": 9,\n",
       "  \"eps_exp\": -5,\n",
       "  \"hid_exp\": 9,\n",
       "  \"l2_exp\": -5,\n",
       "  \"layers_n\": 1,\n",
       "  \"lr_exp\": -2,\n",
       "  \"opt_code\": \"Adam\"\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n/best validation auc: 0.7941332843739122\n",
      "n/best test auc: 0.7964534342513292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7941332843739122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuned model auc results:\n",
    "evaluate_model(best_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete unwanted experiments \n",
    "experiment = conn.experiments('someid').delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
