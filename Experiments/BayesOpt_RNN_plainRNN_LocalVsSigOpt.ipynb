{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to confirm whether we can achieve the same result (best validation AUC) locally on the server based on the best parameters so far searched on SigOpt.com\n",
    "* Model searched: RNN with RNN cell. SigOpt gives Validation AUC of **0.803**\n",
    "* Hyperparameters tested: dropout: **0.75457543972787**; embdim_exp: **9**; eps_exp: **-4**; hid_exp: **9**; l2_exp: **-5**; layers_n: **1**; lr_exp: **-3**; opt_code: **RMSprop**  [click here](https://sigopt.com/guest?guest_token=JXVRREUZOUEXOLLHIBUNTCEWFXQPQQSFUVMLBFKXMDCICYYY)\n",
    "* Result: Using the same set of parameters, local BO with gp_param = 1e-14 (we tried 1e-4~1e-15) gives a best validation auc of 0.70582(first point), which is quite different from the SigOpt. While the exact mechanism differences are unkown, we speculate that it might be because that our local BO package only utilizes Matern kernel from sklearn, and alpha (noise level to the kernel) is the only parameter that we can control for Gaussian process, while [this paper](https://static.sigopt.com/b/20a144d208ef255d3b981ce419667ec25d8412e2/pdf/SigOpt_Bayesian_Optimization_Primer.pdf) indicates that SigOpt draws on current open sources including SPEARMINT,MOE, HYPEROPT, SMAC, and therefore likely to be more flexible in choosing best Gaussian process to optimize target function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_HPS as model #this changed\n",
    "import Loaddata_final as Loaddata\n",
    "import TrVaTe as TVT #This changed \n",
    "\n",
    "# check GPU availability\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing data...\n",
      "\n",
      "Sample data after split:\n",
      "[0, [[1667, 144, 62, 85], [1667, 144, 62, 85]]]\n",
      "model is RNN_GRU\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "set_x = pickle.load(open('Data/h143.visits', 'rb'), encoding='bytes')\n",
    "set_y = pickle.load(open('Data/h143.labels', 'rb'),encoding='bytes')\n",
    "\n",
    "\"\"\"\n",
    "model_x = []\n",
    "for patient in set_x:\n",
    "    model_x.append([each for visit in patient for each in visit])  \n",
    "    \n",
    "\"\"\"\n",
    "model_x = set_x  #this is for the rest of the models\n",
    "    \n",
    "merged_set= [[set_y[i],model_x[i]] for i in range(len(set_y))] #list of list or list of lists of lists\n",
    "print(\"\\nLoading and preparing data...\")    \n",
    "train1, valid1, test1 = Loaddata.load_data(merged_set)\n",
    "print(\"\\nSample data after split:\")  \n",
    "print(train1[0])\n",
    "print(\"model is\", 'RNN_GRU') #can change afterwards, currently on most basic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print2file(buf, outFile):\n",
    "    outfd = open(outFile, 'a')\n",
    "    outfd.write(buf + '\\n')\n",
    "    outfd.close()\n",
    "\n",
    "logFile='RNN_plain_confirmation.log'\n",
    "header = 'Model|EmbSize|CellType|n_Layers|Hidden|Dropout|Optimizer|LR|L2|EPs|BestValidAUC|TestAUC|atEpoch'\n",
    "print2file(header, logFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tune(dlm_code, ct_code, opt_code, embdim_exp, hid_exp, layers_n, dropout, l2_exp , lr_exp, eps_exp):\n",
    "    #little transformations to use the searched values\n",
    "    embed_dim = 2** int(embdim_exp)\n",
    "    hidden_size = 2** int(hid_exp)\n",
    "    n_layers = int(layers_n)\n",
    "    dropout = round(dropout, 4)\n",
    "    l2 = 10** int(l2_exp)\n",
    "    lr = 10** int(lr_exp)\n",
    "    eps = 10** int(eps_exp)\n",
    "\n",
    "        \n",
    "    #dealing with categorical data\n",
    "    if int(dlm_code)<3:\n",
    "      if int(ct_code) ==1:\n",
    "          cell_type='RNN'   \n",
    "      elif int(ct_code) ==2:\n",
    "          cell_type='LSTM'\n",
    "      elif int(ct_code) ==3:\n",
    "          cell_type='GRU'\n",
    "      \n",
    "    if int(dlm_code)==1:\n",
    "        w_model='RNN'\n",
    "        ehr_model = model.EHR_RNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type)\n",
    "    elif int(dlm_code)==2:\n",
    "        w_model='DRNN'\n",
    "        ehr_model = model.DRNN(20000, embed_dim, hidden_size, n_layers, dropout, cell_type)\n",
    "\n",
    "    if use_cuda:\n",
    "        ehr_model = ehr_model.cuda(0)    \n",
    "        \n",
    "        \n",
    "    if int(opt_code) ==1:\n",
    "        opt= 'Adadelta'\n",
    "        optimizer = optim.Adadelta(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps) ## rho=0.9\n",
    "    elif int(opt_code) ==2:\n",
    "        opt= 'Adagrad'\n",
    "        optimizer = optim.Adagrad(ehr_model.parameters(), lr=lr, weight_decay=l2) ##lr_decay no eps\n",
    "    elif int(opt_code) ==3:\n",
    "        opt= 'Adam'\n",
    "        optimizer = optim.Adam(ehr_model.parameters(), lr=lr, weight_decay=l2,eps=eps ) ## Beta defaults (0.9, 0.999), amsgrad (false)\n",
    "    elif int(opt_code) ==4:\n",
    "        opt= 'Adamax'\n",
    "        optimizer = optim.Adamax(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps) ### Beta defaults (0.9, 0.999)\n",
    "    elif int(opt_code) ==5:\n",
    "        opt= 'RMSprop'\n",
    "        optimizer = optim.RMSprop(ehr_model.parameters(), lr=lr, weight_decay=l2 ,eps=eps)                \n",
    "    elif int(opt_code) ==6:\n",
    "        opt= 'ASGD'\n",
    "        optimizer = optim.ASGD(ehr_model.parameters(), lr=lr, weight_decay=l2 ) ### other parameters\n",
    "    elif int(opt_code) ==7:\n",
    "        opt= 'SGD'\n",
    "        optimizer = optim.SGD(ehr_model.parameters(), lr=lr, weight_decay=l2 ) ### other parameters\n",
    "  \n",
    "    \n",
    "    bestValidAuc = 0.0\n",
    "    bestTestAuc = 0.0\n",
    "    bestValidEpoch = 0\n",
    "  \n",
    "    for ep in range(epochs):\n",
    "        current_loss, train_loss = TVT.train(train1, model= ehr_model, optimizer = optimizer, batch_size = 200)\n",
    "        avg_loss = np.mean(train_loss)\n",
    "        valid_auc, y_real, y_hat  = TVT.calculate_auc(model = ehr_model, data = valid1, which_model = w_model, batch_size = 200)\n",
    "        if valid_auc > bestValidAuc: \n",
    "            bestValidAuc = valid_auc\n",
    "            bestValidEpoch = ep\n",
    "            best_model= ehr_model\n",
    "            #bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = ehr_model, data = test1, which_model = w_model, batch_size = 200)\n",
    "\n",
    "        if ep - bestValidEpoch > 12:\n",
    "            break\n",
    "      \n",
    "\n",
    "    fname= w_model+'E'+str(embed_dim)+cell_type+'L'+str(n_layers)+'H'+str(hidden_size)+'D'+str(dropout)+opt+'L'+str(lr)+'P'+str(l2)  \n",
    "    bmodel_pth='models/'+fname\n",
    "    bestTestAuc, y_real, y_hat = TVT.calculate_auc(model = best_model, data = test1, which_model = w_model, batch_size = 200)\n",
    "    torch.save(best_model, bmodel_pth)\n",
    "    buf = '|%f |%f |%d ' % (bestValidAuc, bestTestAuc, bestValidEpoch )\n",
    "    \n",
    "    pFile= w_model+'|'+str(embed_dim)+'|'+cell_type+'|'+str(n_layers)+'|'+str(hidden_size)+'|'+str(dropout)+'|'+opt+'|'+str(lr)+'|'+str(l2)+'|'+str(eps)+ buf  \n",
    "    print2file(pFile, logFile)\n",
    "    \n",
    "    return bestValidAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Now Tuning model with Bayesian Optimization:  cell code 1 model code 1 optimizer code 5\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   ct_code |   dlm_code |   dropout |   embdim_exp |   eps_exp |   hid_exp |    l2_exp |   layers_n |    lr_exp |   opt_code | \n",
      "    1 | 09m06s | \u001b[35m   0.70582\u001b[0m | \u001b[32m   1.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m   0.7546\u001b[0m | \u001b[32m      9.0000\u001b[0m | \u001b[32m  -4.0000\u001b[0m | \u001b[32m   9.0000\u001b[0m | \u001b[32m  -5.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m  -3.0000\u001b[0m | \u001b[32m    5.0000\u001b[0m | \n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   ct_code |   dlm_code |   dropout |   embdim_exp |   eps_exp |   hid_exp |    l2_exp |   layers_n |    lr_exp |   opt_code | \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e-14} #change this noise level\n",
    "\n",
    "#Here we loop through different models, change the model tune \n",
    "for cti in range(1,2):  #Just plainRNN (==1)\n",
    "    for dlmi in range(1,2):#just RNN (==1)\n",
    "        for opti in range(5,6): #RMSprop \n",
    "            print('\\n Now Tuning model with Bayesian Optimization: ','cell code', str(cti),'model code', str(dlmi),'optimizer code',str(opti))\n",
    "            NNBO = BayesianOptimization(model_tune,\n",
    "                                        {'dlm_code':(dlmi,dlmi), 'ct_code': (cti, cti), 'opt_code':(opti, opti),\n",
    "                                         'embdim_exp': (5, 9),'hid_exp': (5, 9),'layers_n': (1, 3),'dropout': (0, 1),\n",
    "                                         'l2_exp': (-6, -1), 'lr_exp': (-7, -2), 'eps_exp': (-9, -4)})\n",
    "            NNBO.explore({'dlm_code':[dlmi], 'ct_code': [cti], 'opt_code':[opti],'embdim_exp': [9],\n",
    "                          'hid_exp': [9],'layers_n': [1],'dropout': [0.75457543972787],'l2_exp': [-5], 'lr_exp': [-3], 'eps_exp':[-4]},\n",
    "                          eager = True)\n",
    "\n",
    "            NNBO.maximize(n_iter=5, **gp_params)\n",
    "\n",
    "            print('-' * 53)\n",
    "            print('Final Results')\n",
    "            print('RNN / DRNN: %f' % NNBO.res['max']['max_val'])\n",
    "\n",
    "            print2file(str(NNBO.res['max']), logFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
